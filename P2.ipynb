{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the materials in this instruction notebook are adapted from \"Introduction to Machine Learning with Python\" by Andreas C. Mueller and Sarah Guido.\n",
    "\n",
    "To run the examples in this notebook and to finish your assignment, you need a few Python modules. If you already have a Python installation set up, you can use pip to install all of these packages:\n",
    "\n",
    "$ pip install numpy matplotlib ipython jupyter scikit-learn pandas graphviz\n",
    "\n",
    "In your python code, you will always need to import a subset of the following modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset that we use in this notebook is included in scikit-learn, a popular machine learning library for Python. The dataset is the Wisconsin Breast Cancer dataset, which records clinical measurements of breast cancer tumors. Each tumor is labeled as “benign” (for harmless tumors) or “malignant” (for cancerous tumors), and the task is to learn to predict whether a tumor is malignant based on the measurements of the tissue.\n",
    "\n",
    "The data can be loaded using the load_breast_cancer function from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys(): dict_keys(['target', 'target_names', 'DESCR', 'data', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys(): {}\".format(cancer.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets that are included in scikit-learn are usually stored as Bunch objects, which contain some information about the dataset as well as the actual data. All you need to know about Bunch objects is that they behave like dictionaries, with the added benefit that you can access values using a dot (as in bunch.key instead of bunch['key'])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 569 data points, with 30 features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cancer data: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of cancer data: {}\".format(cancer.data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these 569 data points, 212 are labeled as malignant and 357 as benign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts per class:\n",
      "{'benign': 357, 'malignant': 212}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample counts per class:\\n{}\".format(\n",
    "      {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a description of the semantic meaning of each feature, we can have a look at the feature_names attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature names:\\n{}\".format(cancer.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the names of the features (attributes) and the values in the target (class attribute), and the first 3 instances in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension'] ['malignant' 'benign']\n",
      "[  1.79900000e+01   1.03800000e+01   1.22800000e+02   1.00100000e+03\n",
      "   1.18400000e-01   2.77600000e-01   3.00100000e-01   1.47100000e-01\n",
      "   2.41900000e-01   7.87100000e-02   1.09500000e+00   9.05300000e-01\n",
      "   8.58900000e+00   1.53400000e+02   6.39900000e-03   4.90400000e-02\n",
      "   5.37300000e-02   1.58700000e-02   3.00300000e-02   6.19300000e-03\n",
      "   2.53800000e+01   1.73300000e+01   1.84600000e+02   2.01900000e+03\n",
      "   1.62200000e-01   6.65600000e-01   7.11900000e-01   2.65400000e-01\n",
      "   4.60100000e-01   1.18900000e-01] 0\n",
      "[  2.05700000e+01   1.77700000e+01   1.32900000e+02   1.32600000e+03\n",
      "   8.47400000e-02   7.86400000e-02   8.69000000e-02   7.01700000e-02\n",
      "   1.81200000e-01   5.66700000e-02   5.43500000e-01   7.33900000e-01\n",
      "   3.39800000e+00   7.40800000e+01   5.22500000e-03   1.30800000e-02\n",
      "   1.86000000e-02   1.34000000e-02   1.38900000e-02   3.53200000e-03\n",
      "   2.49900000e+01   2.34100000e+01   1.58800000e+02   1.95600000e+03\n",
      "   1.23800000e-01   1.86600000e-01   2.41600000e-01   1.86000000e-01\n",
      "   2.75000000e-01   8.90200000e-02] 0\n",
      "[  1.96900000e+01   2.12500000e+01   1.30000000e+02   1.20300000e+03\n",
      "   1.09600000e-01   1.59900000e-01   1.97400000e-01   1.27900000e-01\n",
      "   2.06900000e-01   5.99900000e-02   7.45600000e-01   7.86900000e-01\n",
      "   4.58500000e+00   9.40300000e+01   6.15000000e-03   4.00600000e-02\n",
      "   3.83200000e-02   2.05800000e-02   2.25000000e-02   4.57100000e-03\n",
      "   2.35700000e+01   2.55300000e+01   1.52500000e+02   1.70900000e+03\n",
      "   1.44400000e-01   4.24500000e-01   4.50400000e-01   2.43000000e-01\n",
      "   3.61300000e-01   8.75800000e-02] 0\n"
     ]
    }
   ],
   "source": [
    "print(cancer.feature_names,cancer.target_names)\n",
    "for i in range(0,3):\n",
    "    print(cancer.data[i], cancer.target[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out more about the data by reading cancer.DESCR if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor\n",
    "#### k-Neighbors Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s look at how we can apply the k-nearest neighbors algorithm using scikit-learn. First, we split our data into a training and a test set so we can evaluate generalization performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this function randomly partitions the dataset into training and test sets. The randomness is controlled by a pseudo random number generator, which generates random numbers using a seed. If you fix the seed, you will actually always get the same partition (thus no randomness). That is why we set random_state=0. (We can also use any other fixed number instead of 0, to acheive the same effect.) It guarantees that you reproduce the same results in every run. It is useful in testing your programs. However, in your real production code where randomness is needed, you shouldn't fix random_state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the KNeighborsClassifier class. This is when we can set parameters, like the number of neighbors to use. Here, we set it to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the classifier using the training set. For KNeighborsClassifier this means storing the dataset, so we can compute neighbors during prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_feature, train_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions on the test data, we call the predict method. For each data point in the test set, this computes its nearest neighbors in the training set and finds the most common class among these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      "[0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set predictions:\\n{}\".format(knn.predict(test_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how well our model generalizes, we can call the score method with the test data together with the test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy: {:.2f}\".format(knn.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model is about 92% accurate, meaning the model predicted the class correctly for 92% of the samples in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s investigate whether we can confirm the connection between model complexity and generalization. For that, we evaluate training and test set performance with different numbers of neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xd4VNXWwOHfnlCSUEKJVKmhE1qCiEi1AIoCAioTAekq\nIhpURLwXBaXYQPBauH4iYEwQBWkWUERFJegNiIQiaAjYQBAJNZCyvj9OEjJppExyJsl6n2ceM3v2\n2WedKM5iVyMiKKWUUkp5CofdASillFJKpafJiVJKKaU8iiYnSimllPIompwopZRSyqNocqKUUkop\nj6LJiVJKKaU8iiYnSimllPIompwopZRSyqNocqKUUkopj6LJiVJKKaU8ikckJ8aYbsaYtcaY340x\nycaY/rm4pqcxJsoYE2+M2W+MuTuLOrcbY/YaY84bY3YaY24qnCdQSimllLt4RHICVAB+ACYAlz3s\nxxjTEFgPbALaAQuA/zPG3JiuThcgHHgDaA+sAVYbY1q5OXallFJKuZHxtIP/jDHJwEARWZtDnWeB\nm0SkbbqyCMBPRG5Oeb8c8BWR/unqbAV2iMiEQnsApZRSShWIp/Sc5FVn4LMMZRuAa9K9vyYXdZRS\nSinlYcrYHUA+1QKOZig7ClQ2xpQXkQs51KmVXaPGmOpAHyAWiHdbtEoppVTJ5w00BDaIyN8Faai4\nJieFpQ/wjt1BKKWUUsXYXVhzPvOtuCYnR4CaGcpqAqdSek1yqnMkh3ZjAZYsCaNNm5ZuCNNeoaGh\nzJ8/3+4w3Eafx3OVpGeBkvU8JelZQJ/Hk+3du5dhw4ZByndpQRTX5GQrkHFZcO+U8vR1rgcWpiu7\nMUOdjOIB9uxpyd13B7khTHv5+fkRFFT8nyOVPo/nKknPAiXreUrSs4A+TzFR4GkRHjEh1hhTwRjT\nzhjTPqWoccr7eimfzzHGLE13yespdZ41xjQ3xkwAhgDz0tVZAPQ1xkxOqfMUEAz853LxvPEGnDnj\njidTSimlVF55RHICdAR2AFFY+5y8CGwHZqR8Xguol1pZRGKBfsANWPujhAJjROSzdHW2AiHA+JQ6\ng4ABIrLncsGcOQMlpJdNKaWUKnY8YlhHRL4kh0RJREZlUfYVVk9ITu2uBFbmNZ477oDnn4f77gN/\n/7xerZRSSqmC8JSeE48yKiUVmj3b3jgKyul02h2CW+nzeK6S9CxQsp6nJD0L6POUFh63Q6ydjDFB\nQFRUVBQffhjEM8/AgQNQv77dkSmllFKebfv27QQHBwMEi8j2grTlEcM6nig0FP7zH3jqKVi82O5o\nlFKF4fDhwxw/ftzuMJQqFvz9/alfRH9b1+QkGxUrwr//DQ8+CI88Aq30uEClSpTDhw/TsmVLzp07\nZ3coShULvr6+7N27t0gSFE1OcjB+PLz4IjzxBHzwgd3RKKXc6fjx45w7d46wsDBatiz+my4qVZhS\nN1g7fvy4Jid2K1cOnn4ahg+HyEjo3NnuiJRS7tayZcuSuAmWUsWarta5jJAQaNsWpk4FnTuslFJK\nFT5NTi7D4bCWFH/5JWzYYHc0SimlVMmnyUku3HwzdO0Kjz8Oycl2R6OUUkqVbJqc5IIxMHcu/PAD\nvPuu3dEopZRSJZsmJ7l07bVw663wr3/BxYt2R6OUUvZp2LAho0ePzte1PXv2pFevXm6OSJU0mpzk\nwaxZcPAgvPmm3ZEopVT2tm7dyowZMzh16lShtO9wODDG5OtaYwwOh371qJzpUuI8aNPGWlY8cyaM\nGAEVKtgdkVJKZfbtt98yc+ZMRo0aReXKld3e/k8//ZTvBOPTTz91czSqJNL0NY9mzIC//4YFC+yO\nRCmlspaXM9NEhAsXLuSp/bJly+Ll5ZXXsAAoU6YMZcro34svJykpiYSEBLvDsI0mJ3nUsCHcdx88\n+6yVpCillCeZMWMGU6ZMAay5IQ6HAy8vLw4fPgxYQzKTJk0iPDycwMBAvL292ZCyT8ILL7zAtdde\ni7+/P76+vnTs2JGVK1dmukfGOSdLly7F4XDw7bffMnnyZGrUqEHFihUZNGgQf2f4H2XPnj257rrr\n0t5/+eWXOBwO3nvvPWbNmkW9evXw8fHhhhtu4Jdffsl071deeYWAgAB8fX3p3LkzX3/9daY2s/PW\nW29x/fXXU7NmTby9vWndujWvv/56lnU//vhjevToQeXKlfHz86NTp05ERES41Nm2bRs333wz1apV\no2LFirRr146FCxdm+6ypRo4cSaNGjdLeHzp0CIfDwbx581iwYAFNmjTB29ubvXv3kpCQwPTp0+nY\nsSNVqlShYsWKdO/enS+++CJTuyLCggULaNu2LT4+PtSoUYObbrqJ7du3p8XTvn37LJ+3efPm3HTT\nTZf9HRYVTV/z4YknrMMA586F55+3OxqllLpk8ODB7N+/n+XLl7NgwQKqV68OwBVXXJFWZ9OmTaxY\nsYKJEyfi7+9Pw4YNAVi4cCEDBgxg2LBhXLx4keXLl3PHHXewfv16ly+u7OabPPDAA1SrVo2nnnqK\n2NhY5s+fz8SJE12+1LO7du7cuXh5efHoo48SFxfHs88+y7Bhw9i6dWtanddee40HHniAHj16MHny\nZGJjYxk4cCBVq1alXr16l/3dvP766wQGBjJgwADKlCnDunXrmDBhAiLCfffdl1ZvyZIljBkzhsDA\nQKZNm0aVKlXYsWMHGzZswOl0Atbw1K233kqdOnV46KGHqFWrFnv37uXDDz9k0qRJOT6rMSbLzxYv\nXsyFCxe45557KF++PNWqVePUqVMsXrwYp9PJ+PHjOX36NG+++SZ9+/blu+++o23btmnXjx49mqVL\nl9KvXz/GjRtHYmIiW7ZsITIykqCgIIYPH8748ePZs2cPrdIdGPf9999z4MABnnzyycv+DouMiOgr\n5QUEARIVFSWX8+STIuXLi/z662WrKqU8UFRUlOT2z3tx88ILL4jD4ZBDhw5l+swYI2XKlJF9+/Zl\n+iw+Pt7lfWJiorRp00ZuuOEGl/KGDRvKqFGj0t4vWbJEjDHSp08fl3qTJ0+WsmXLyqlTp9LKevbs\nKb169Up7/8UXX4gxRlq3bi2JiYlp5QsXLhSHwyG7d+8WEZGLFy+Kv7+/dO7cWZKSktLqLVu2TIwx\nLm1mJ+PziYj07dtXmjRpkvY+Li5OKleuLF26dJELFy5k2U5SUpI0atRIGjdu7PJsGWV81lQjR46U\nRo0apb2PjY0VY4xUqVJF/v77b5e6ycnJkpCQ4FIWFxcntWrVkrFjx6aVff7552KMkdDQ0GzjiYuL\nEx8fH3n88cddyidNmiSVKlWSc+fOZXttbv68pNYBgqSA38fac5JPkyfDK69Yc1DeeMPuaJRShenc\nOdi3r/Dv06IF+PoW/n169uxJ8+bNM5WXL18+7eeTJ0+SmJhIt27dWL58+WXbNMYwfvx4l7Ju3brx\n0ksvcejQIQIDA3O8fvTo0S7zWLp164aIEBMTQ6tWrfjf//7H33//zbPPPusyGTckJISHHnrosvFl\nfL5Tp06RkJBA9+7d2bhxI6dPn6ZSpUp8+umnnDlzhqlTp1KuXLks29mxYwexsbEsWLCASpUq5ere\nuTFkyBCqVavmUmaMSZujIyKcPHmSpKQkOnbsmDZcA7By5UocDgfTp0/Ptv3KlSszYMAAIiIimD17\nNgDJycmsWLGC2267DR8fH7c9S0FpcpJPlStbe55MngwPP2z9T0UpVTLt2wfBwYV/n6goKIozCFOH\ncTJav349s2bN4ocffnCZJJvblTkZh1aqVq0KwD///FPgaw8dOoQxhoCAAJd6Xl5e2T5PRt988w1P\nPvkkkZGRnDt3Lq3cGENcXByVKlVKm+fSunXrbNv55ZdfMMbkWCc/snuOpUuXMm/ePPbt2+cySbZx\n48ZpP8fExFCnTh2qVKmS4z1GjBjBihUr+Prrr+natSuffvopf/31F8OHD3fLM7iLJicFcO+9MG+e\nlaS8/77d0SilCkuLFlbiUBT3KQpZ/Q15y5YtDBgwgJ49e/Laa69Ru3ZtypYty+LFizNNBM1Odit4\nJBerhwpybW7ExMRwww030LJlS+bPn0+9evUoV64cH374IS+99BLJhXA2SXZzTpKSkrIsz+rfS1hY\nGKNGjWLQoEFMmTKFGjVq4OXlxezZs4mJiclzTH369KFGjRqEhYXRtWtXwsLCqFWrFtdff32e2ypM\nmpwUQPny1p4nI0fC99/DVVfZHZFSqjD4+hZNj4a75GeDtFWrVuHj48OGDRtclvq+6SG7TjZo0AAR\n4eeff6ZHjx5p5UlJScTGxtKuXbscr1+3bh0XL15k3bp11K1bN61806ZNLvUCAgIQEaKjo116JrKr\nk9MqoapVq3Lw4MFM5YcOHcox1vRWrlxJQEAA72f4G3DG4ZuAgAA2btzIyZMnc+w9cTgchISEsHTp\nUubOncuaNWu455578r2pXmHRpcQFNGwYtG4NU6eCmxJ8pZQqkAopO0SePHky19d4eXlhjCExMTGt\nLDY2ljVr1rg9vvzo2LEj1atX54033nDp5QgLC8vVsFFqz0z6a+Pi4liyZIlLvd69e1OpUiXmzJmT\n7f4vQUFBNGrUiJdeeom4uLhs7xkQEMC+fftcllPv3LmTb7755rLxZow7vW3btrmsYgJrlVZycjIz\nZsy4bJvDhw/nxIkT3HPPPZw9e5a77ror1/EUFe05KSAvL5g9GwYMgM8+gxtvtDsipVRpFxwcjIgw\nbdo0hg4dStmyZenfv3+OEx779evHvHnz6NOnDyEhIRw9epRXX32Vpk2b8uOPP172ntkNv7hrWKZs\n2bI89dRTTJo0iV69enHHHXcQGxvLW2+9RZMmTS77N//evXtTtmxZbrnlFu655x5Onz7N//3f/1Gz\nZk2OHDmSVq9SpUrMnz+fcePGcdVVVxESEkLVqlXZuXMn58+f56233sIYw2uvvUb//v1p3749o0aN\nonbt2uzbt489e/bw8ccfA9Yk33nz5tG7d2/GjBnD0aNHWbRoEYGBgbk+WuCWW25h1apVDBw4kH79\n+hETE8OiRYto3bo1Z86cSavXs2dPhg8fzsKFC9m/fz99+/YlOTmZLVu2cN111zFhwoS0uu3btycw\nMJD33nuPVq1aZbv3iZ2058QNbr0VunSBxx+HQhi2VEqpPOnYsSPPPPMMP/74I6NGjSIkJIRjx44B\n2e+x0atXLxYvXszRo0cJDQ3l3Xff5bnnnmPgwIGZ6mbVRk57elyuLLfX3n///SxcuJBff/2VRx99\nlK+++oq1a9fi5+eHt7d3lm2katasWdqKlkcffZT//ve/3HvvvWl7kqQ3evTotHafeeYZpk6dyo4d\nO1z2eunduzebN2+mefPmzJs3j4cffpjPP/+c/v37p9Vp0aIFb7/9NqdOneLhhx9m/fr1hIWF0aFD\nhyx/B1n9HkaOHMmcOXP48ccfefDBB/n000955513CA4OzlR/yZIlPP/888TGxjJlyhTmzJlDfHw8\nXbp0ydTuiBEjXP7paYy7stqSwBgTBERFRUURlMcB5i1boHt3ePdduOOOwolPKeU+27dvJzg4mPz8\neVeeQ0S44oorGDx4MIsWLbI7nGJjwYIFPPzww8TGxnLllVdetn5u/ryk1gGCRWR7lpVySXtO3KRb\nN7j5ZmvlTik+DkEppQpNVnNAli5dyokTJ+jVq5cNERVfixcvpmfPnrlKTOygc07caPZs6NAB3noL\nMuxFpJRSqoAiIyMJDQ3l9ttvp3r16kRFRbF48WLatm3LkCFD7A7P4507d441a9awefNmoqOjWbt2\nrd0hZUuTEzdq1w5CQuCpp6xVPEWx06NSSpUWDRs2pH79+rz88sucOHGCatWqpc3J0JOOL+/YsWPc\nddddVK1alSeeeIJ+/frZHVK29N+mm82cac07eflleOwxu6NRSqmSo0GDBqxevdruMIqtBg0aFMpm\nc4VB55y4WePGcM891onFuVh6r5RSSqkMNDkpBP/+tzUp9tln7Y5EKaWUKn40OSkENWtCaCgsWAC/\n/253NEoppVTxoslJIXnkEahQAZ5+2u5IlFJKqeJFk5NC4ucH06bB//0f7N9vdzRKKaVU8aHJSSGa\nMAFq17bmoCillFIqdzQ5KUTe3jBjBqxYAVFRdkejlFJKFQ+anBSyESOgZUvrUECllFJKXZ4mJ4Ws\nTBmYNQs+/RQ2bbI7GqVUabB161ZmzJjBqVOnCvU+c+bMYc2aNYV6D1U6aXJSBAYOhKuvtnpP9BBo\npVRh+/bbb5k5cyYnT54s1PvMnj1bkxNVKDQ5KQLGWDvGfv89rFpldzRKqZJO9G9BBXbu3Dm7QyjV\nNDkpIj17Qp8+8MQTkJhodzRKqZJqxowZTJkyBbAOynM4HHh5eXH48OG0OmFhYXTs2BFfX1+qV6+O\n0+nkt99+c2nn559/ZvDgwdSuXRsfHx/q1auH0+nk9OnTADgcDs6dO8eSJUtwOBw4HA5Gjx6dbVwJ\nCQlMnz6djh07UqVKFSpWrEj37t354osvMtUVERYsWEDbtm3x8fGhRo0a3HTTTWzfvt2lXlhYGFdf\nfTUVKlSgWrVq9OjRg08//TTtc4fDwcyZMzO137BhQ5dYly5disPh4KuvvmLChAnUrFmTevXqAXD4\n8GEmTJhAixYt8PX1xd/fnzvuuINDhw5lajcuLo7Q0FAaNWqEt7c39erV4+677+bEiROcPXuWihUr\nEhoamum633//nTJlyvCsbiuexmMO/jPG3A88AtQCdgIPiMj3l6l/P9AQOATMFpG3M9R5CLgXqA8c\nB94HHheRC4XxDJczZw4EBcHSpTBmjB0RKKVKusGDB7N//36WL1/OggULqF69OgBXXHEFALNmzWL6\n9OkMHTqUcePGcezYMRYuXEiPHj3YsWMHlStXJiEhgd69e5OQkMCkSZOoVasWv//+O+vXr+fkyZNU\nqlSJsLAwxowZw9VXX8348eMBCAgIyDauU6dOsXjxYpxOJ+PHj+f06dO8+eab9O3bl++++462bdum\n1R09ejRLly6lX79+jBs3jsTERLZs2UJkZCRBQUGAlYTNmDGDa6+9lqeffppy5cqxbds2Nm/ezI03\n3pjj78gYk2X5hAkTqFGjBk8++SRnz54F4PvvvycyMhKn08mVV15JbGwsr776Kr169WLPnj14e3sD\ncPbsWbp27cpPP/3EmDFj6NChA8ePH2ft2rX89ttvtG3blttuu413332XefPmucQQHh4OwLBhw3KM\nu1QREdtfwJ1APDACaAEsAk4A/tnUvw84CQzBSk7uBE4B/dLVCQHOp3xWH7gB+A14IYc4ggCJioqS\nwjJ0qEjduiLnzhXaLZRSuRAVFSWF/efdLi+88II4HA45dOiQS/mhQ4ekTJkyMnfuXJfy3bt3S9my\nZWXOnDkiIvLDDz+IMUZWrVqV430qVqwoo0aNylVMycnJkpCQ4FIWFxcntWrVkrFjx6aVff7552KM\nkdDQ0Gzb+vnnn8XLy0uGDBmS4z2NMTJjxoxM5Q0bNnSJe8mSJWKMkR49ekhycrJL3fj4+EzXb9u2\nTYwxEhYWllY2ffp0cTgcsmbNmmzj2bhxozgcDtmwYYNLebt27aRXr145PovdcvPnJbUOECQFzAs8\npeckFFgkIssAjDH3Av2A0cBzWdQfllL//ZT3scaYq4DHgA9Tyq4BvhaRd1PeHzbGLAc6FdIz5MrT\nT1tLi195xdriXinl+c4lnGPf8X2Ffp8W/i3wLetbaO2vXLkSEeH222/n77//TiuvUaMGTZs2ZfPm\nzUydOhU/Pz8APvnkE/r27YuPj0+B722MoUwZ6ytHRDh58iRJSUl07NjRZbhm5cqVOBwOpk+fnm1b\nH3zwASKSY538xDdu3LhMvSrly5dP+zkxMZFTp07RuHFjqlSpwvbt27nrrrsAWLVqFe3ataN///7Z\n3uOGG26gdu3avPPOO/Tu3RuA6OhofvzxR9588023PUtJYHtyYowpCwQDs1PLRESMMZ9hJRhZKY/V\n05JePNDJGOMlIknAt8BdxpirROR7Y0xj4GZgqdsfIg+aNIGxY2H2bOufVarYGY1SKjf2Hd9H8H+D\nC/0+UeOjCKodVGjt//zzzyQnJ9OkSZNMnxljKFeuHGDNyXj44YeZN28eYWFhdOvWjf79+zNs2DAq\nV66c7/svXbqUefPmsW/fPhISEtLKGzdunPZzTEwMderUoUoO/3OMiYnB4XDQsmXLfMeSlYYNG2Yq\ni4+PZ/bs2SxZsoTff/89bbKxMYa4uLi0er/88gtDhgzJsX1jDHfddRevv/468fHxeHt788477+Dj\n43PZa0sb25MTwB/wAo5mKD8KNM/mmg3AWGPMGhHZbozpCIwByqa0d1REIowx/sDXxkqFvYDXRcT2\nGUfTp1vzTp5/3toDRSnl2Vr4tyBqfOFv89zCv0Whtp+cnIzD4eCTTz7B4ci8HqJixYppPz///POM\nHDmSNWvWsHHjRiZNmsTcuXOJjIykTp06eb53WFgYo0aNYtCgQUyZMoUaNWrg5eXF7NmziYmJKdBz\n5VVSUlKW5Vn1EE2cOJGlS5cSGhpK586d8fPzwxjDnXfeSXJycp7vPWLECJ5//nlWr17N0KFDiYiI\n4NZbb6VSpUp5bqsk84TkJD+eBmoCW40xDuAIsASYAiQDGGN6AtOwJsR+BzQBFhpj/hSRZ3JqPDQ0\nNK1bM5XT6cTpdLol+Nq14aGH4KWXYOJE671SynP5lvUt1B4Nd8tuwmdAQAAiQsOGDbPsPcmodevW\ntG7dmmnTphEZGUmXLl14/fXX01bAZHefrKxcuZKAgADef/99l/KMQzMBAQFs3LiRkydPZtt7EhAQ\nQHJyMnv27HGZSJtR1apVM+31kpCQwJ9//pmnuEeOHMlzz12aYXDhwoVM7QYEBBAdHX3Z9lq3bk2H\nDh145513qFu3LocPH+aVV17JdTyeIiIigoiICJey9D1JBeUJS4mPA0lYyUZ6NbGSjkxEJF5ExgK+\nQAOsCa+HgNMiciyl2kzgbRF5S0R2i8garGRl6uUCmj9/PmvXrnV5uSsxSTVlCpQvD8/kmCYppVTe\nVahQASDTF+igQYNwOBzMmDEjy+tOnDgBwOnTpzP1LrRu3RqHw8GFC5cWO1aoUCHXG715eXllKtu2\nbRtbt251KRs8eDDJycnZxggwcOBAjDHMnDkzxz1dAgIC+Oqrr1zKFi1alG3PSXZxZ+whWbhwYaY2\nBg8ezM6dO3O1Kd3w4cPZsGEDL730Ev7+/vTt2zfX8XgKp9OZ6Xty/vz5bmvf9p4TEUkwxkQB1wNr\nAVKGYa4HFl7m2iTgj5RrhgLr0n3sC2TcUSS1V8VITv9FF4EqVawdY6dNg9BQay6KUkq5Q3BwMCLC\ntGnTGDp0KGXLlqV///40btyYZ555hmnTpnHw4EEGDhxIpUqViImJYfXq1dxzzz1MnjyZzz//nIkT\nJ3L77bfTrFkzEhMTWbZsGWXKlGHw4MEu9/nss8+YP38+derUoVGjRnTqlPWag1tuuYVVq1YxcOBA\n+vXrR0xMDIsWLaJ169acOXMmrV7Pnj0ZPnw4CxcuZP/+/fTt25fk5GS2bNnCddddx4QJEwgICOCJ\nJ57gmWeeoVu3bgwaNIjy5cvz/fffU7duXWaljJePHTuWe++9lyFDhnDjjTeyc+dONm7cmLasOr3s\nvhJuueUW3n77bSpXrkyrVq3YunUrmzZtwt/f36Xeo48+yvvvv8/tt9/OqFGjCA4O5u+//2bdunUs\nWrSINm3apNUNCQlhypQprF69mgkTJmSZuJV6BV3u444XcAdwDtelxH8DV6R8PgdYmq5+U+AurKGa\nTsBy4BhQP12dJ7GWG9+Jtdz4RuAAEJ5DHIW+lDi9c+dE6tQRcTqL5HZKqXRK8lJiEZFZs2ZJvXr1\npEyZMpmWFX/wwQfSvXt3qVSpklSqVElatWolkyZNkgMHDoiIyMGDB2Xs2LHStGlT8fX1FX9/f7n+\n+utl8+bNLvf46aefpGfPnlKhQgVxOByXXVY8d+5cadSokfj4+EhwcLB89NFHMnLkSGncuLFLveTk\nZHnxxRelVatW4u3tLTVr1pR+/frJjh07XOotWbJEgoODxcfHR6pXry69evWSTZs2ubTz+OOPS40a\nNaRixYpy8803S0xMjDRq1EhGjx7t0o7D4cjyv4W4uDgZM2aM1KhRQypXriw333yz7N+/P1MbIiL/\n/POPTJo0SerVqyfe3t5Sv359GT16tJw4cSJTu/369ROHwyGRkZE5/s48RVEvJTZibwdCGmPMBKw5\nIzWBH7A2YftfymdvAQ1E5LqU9y2AcKAZkABsBh4TkQPp2nMATwDDgbpYycta4F8ikuVpWMaYICAq\nKioqbaOfwvbGGzB+POzYAe3bF8ktlVLA9u3bCQ4Opij/vCuVatCgQURHR7N//367Q8mV3Px5Sa0D\nBIvI9iwr5ZInzDkBQEReFZGGIuIjItekJiYpn41KTUxS3u8TkSARqSgiVUVkUPrEJKVOsog8LSLN\nRKRCStuTsktM7DJqFDRrZg3xKKWUKvn+/PNPPvzwQ0aMGGF3KB7LY5KT0qpMGWs58SefQBZHTCil\nlCohYmNjCQsLw+l0Uq5cubRt/1Vmmpx4gMGDITjY6j3xkFE2pZRSbvbll18yYsQIDh8+zLJly6hR\no4bdIXksTU48gDEwdy5ERkIuVqEppZQqhu6++26Sk5OJiYnhtttuszscj6bJiYe44QbrNW0a5GEJ\nvlJKKVXiaHLiQWbPhr174e237Y5EKaWUso8mJx7kqqtgyBB48kmIz3isoVJKKVVKaHLiYZ55Bn7/\nHV57ze5IlFJKKXvYvn29ctW8OYwebS0vHjMGCnA6uVIqF/bu3Wt3CEp5vKL+c6LJiQd68klr3smL\nL0IOZ18ppQrA398fX19fhg0bZncoShULvr6+mc4UKiyanHigunVh0iQrOZkwAWpmPK9ZKVVg9evX\nZ+/evRw/ftzuUJQqFvz9/alfv36R3EuTEw/12GOwaJE1vLMwx7OZlVL5Vb9+/SL7n61SKvd0QqyH\nqlbNSlARjzArAAAgAElEQVRefx0OHrQ7GqWUUqroaHLiwR58EPz9Yfp0uyNRSimlio4mJx7M19dK\nTN55B3780e5olFJKqaKhyYmHGzMGAgLgiSfsjkQppZQqGpqceLiyZa2N2davh6+/tjsapZRSqvBp\nclIM3H47dOgAU6eCiN3RKKWUUoVLk5NiwOGAOXPgm2/gww/tjkYppZQqXJqcFBO9e0OvXvD445CU\nZHc0SimlVOHR5KSYMMbqPYmOhvBwu6NRSimlCo8mJ8XI1VfDbbdZy4svXLA7GqWUUqpwaHJSzMya\nBYcPW1vbK6WUUiWRJifFTMuWMHKktbz49Gm7o1FKKaXcT5OTYuipp+DUKZg/3+5IlFJKKffT5KQY\nqlcPJk6E55+HY8fsjkYppZRyL01OiqnHH7f2P5k92+5IlFJKKffS5KSYql4dHn0UXn0VDh2yOxql\nlFLKfTQ5KcYeegiqVoUnn7Q7EqWUUsp9NDkpxipWhH//G5YtszZnU0oppUoCTU6KuXHjoFEj+Ne/\n7I5EKaWUcg9NToq5cuXg6adhzRr49lu7o1FKKaUKTpOTEmDoUGjbFqZOBRG7o1FKKaUKRpOTEsDh\nsA4F3LIFPvnE7miUUkqpgtHkpIS46Sbo3t3a/yQ52e5olFJKqfzT5KSEMMbqPdm5E5YvtzsapZRS\nKv80OSlBunSB/v2t5cUXL9odjVJKKZU/mpyUMLNnw8GD8MYbdkeilFJK5Y8mJyVM69YwYoS1vPjM\nGbujUUoppfJOk5MSaMYM+OcfK0E5d87uaJRSSqm80eSkBGrQACZPhueeAz8/6NwZHnkEVq+GY8fs\njk4ppZTKmcckJ8aY+40xB40x540xkcaYq3JRf48x5pwxZq8xZngWdfyMMa8YY/4wxsQbY/YZY/oW\n3lN4jtmzrZU7CxdCQACsWAG33QY1akCLFjB2LCxZAr/8ohu3KaWU8ixl7A4AwBhzJ/AiMB74DggF\nNhhjmonI8Szq3wfMAsYC/wOuBt4wxpwQkQ9T6pQFPgOOAIOAP4AGwMnCfyL7GWPtGtu2Ldx3n1V2\n+DB8/fWl1+LFVmJSqxZ07Xrp1a4dlPGI/zKUUkqVRp7yFRQKLBKRZQDGmHuBfsBo4Lks6g9Lqf9+\nyvvYlJ6Wx4APU8rGAFWAziKSlFJ2uJDiLxbq14eQEOsF1ryUrVsvJSuPPQYXLkCFCnDNNZeSlauv\ntk5AVkoppYqC7clJSg9HMDA7tUxExBjzGXBNNpeVB+IzlMUDnYwxXinJyK3AVuBVY8wA4BgQDjwr\nIrqHKlC1Ktx8s/UCKzH53/8uJSsLFsBTT4GXF3ToAN26WcnKtddCzZq2hq6UUqoEsz05AfwBL+Bo\nhvKjQPNsrtkAjDXGrBGR7caYjlg9JWVT2jsKNAauA8KAm4AmwGtYz/y0ux+iJChf3ko8rr3W6kVJ\nToa9ey8lKx98APPnW3WbNnUdCmra1BpKUkoppQrKE5KT/HgaqAlsNcY4sOaVLAGmAKm9Ig6sJGW8\niAiwwxhzJfAImpzkisNh7ZvSujXcc49V9ttv8M03lxKWJUuseStXXHEpUenWDdq3h7JlbQ1fKaVU\nMeUJyclxIAkr2UivJlbSkYmIxGP1nNyTUu9P4B7gtIikLpb9E7iYkpik2gvUMsaUEZHE7AIKDQ3F\nz8/PpczpdOJ0OnP/VCXUlVfCnXdaL4C4ONd5K088AfHx4OtrLWFOTVg6d4ZKleyNXSmllHtEREQQ\nERHhUhYXF+e29o14wDpSY0wksE1EHkx5b7Amry4Ukedz2cYXwK8iMjzl/SzAKSKN09V5EHhURK7M\npo0gICoqKoqgoKCCPFKpdfEibN/uuiro77+tXpj27V2HgmrXtjtapZRS7rJ9+3aCg4MBgkVke0Ha\n8oSeE4B5wBJjTBSXlhL7Yg3VYIyZA9QRkbtT3jcFOgHbgGrAZKA1MCJdm68B9xtjFgIvA82Ax4GX\niuB5Sq1y5axektSN30Tgp59gyxYrUVm/3tp7Baz9V9InK82b67wVpZRSHpKciMgKY4w/MBNrmOYH\noE+6IZpaQL10l3gBD2MlHAnAZqCLiBxO1+Zvxpg+wHxgJ/B7ys9ZLU1WhcQYa9O3Fi1g3Dir7I8/\nXOetvP22Nfm2enXXZCUoyEp2lFJKlS4eMazjKXRYxx6nT0NkpJWobNli/Xz+PHh7W3usdOtmrSCq\nU8fuSN3Hx8da4aSUUiVFSRzWUaVYpUpw443WCyAhAXbsuNSzsmgRPPOMvTEWhptvtpZmN2tmdyRK\nKeVZNDlRHqdsWejUyXpNnmzNW/n5ZzhZgg4e+PlnmDYNAgOtZ3ziCV3NpJRSqTQ5UR7PmJI3BHLV\nVTBwILzwAsyZA8uWWadI33WXTgpWSimPOZVYqdLGxwf+/W9rF96uXWH4cOuf2ws0UquUUsWfJidK\n2axBA1ixAj7/HE6dgo4drR15jx27/LVKKVUSaXKilIfo1cuaCLxggZWsNGsGL78MidnuZayUUiWT\nJidKeZAyZeCBB2D/frjjDnjwQetE6M2b7Y5MKaWKjiYnSnmgK66wllB//721iue666xk5fDhy1+r\nlFLFnSYnSnmw4GBrN92337b2fGnRAmbOtDapU0qpkkqTE6U8nDEwbJh1RtGkSdaGdK1awQcfWHvA\nKKVUSaPJiVLFRKVKMHcuREdDy5YwaBD07m0tRVZKqZJEkxOliplmzeCjj6wTnmNjoW1ba5fZuDi7\nI1NKKffQ5ESpYqpfP6sX5emn4b//tZKWxYutE56VUqo40+REqWKsfHmYOtWaj3LjjTBmDHTuDNu2\n2R2ZUkrlnyYnSpUAdetCWBhs2WKd6ty5M4waBUeO2B2ZUkrlnSYnSpUgXbvC//4Hr78O69ZZQz0v\nvggXL9odmVJK5Z4mJ0qVMF5e1tk8+/fDiBEwZYo1aXbDBrsjU0qp3MlzcmKMaVwYgSil3KtaNfjP\nf6zzemrVgr59YeBAiImxOzKllMpZfnpOfjbGbDbGDDPGeLs9IqWUW7Vta53N8+67EBVlbeD2r3/B\n2bN2R+YZLlyAb7+F556D/v2towOaNYPRo63VT/v362Z3ShW1/CQnQcCPwDzgiDFmkTGmk3vDUkq5\nkzHW2Tz79sGjj8ILL1hb4b/7bun74j150tonZto06N4d/Pzg2mutYwHOnYP77rM2t9u+HcaOhebN\nrZ6nwYNh/nzrvKOEBLufQqmSzUg+/89kjCkD9AdGAn2B/cBi4G0ROeauAIuSMSYIiIqKiiIoKMju\ncJQqNDEx8PDDsHq19QW9cCG0a2d3VIXj11+tc4lSX7t2WQlZzZrWBOLUV7t2ULas67VxcbB166Vr\nt22D+Hjw9bVWRKVe27mztYOvUqXZ9u3bCQ4OBggWke0FaSvfyUlaA8aUByYAc4BywEVgBfCYiPxZ\noMaLmCYnqrTZuBEefNAaurj3XmtDt2rV7I4q/5KTYfdu12Qk9STn5s1dk5GAAKtHKS8uXrR6VLZs\nudT+iRPgcED79la73bpZPTG1a7v/+ZTyZB6RnBhjOgKjgaHAWWAp8CZwJfAkUFlEitVwjyYnqjRK\nSICXX4annrJ6DmbNgnHjrFU/ni4+3hpmSU0Uvv3WGrYpUwaCgi4lC126QI0a7r9/crK1AV76ZCh1\nwnFAgGsy1Lx53pMhpYoTW5MTY8xkYBTQHPgI+D/gIxFJTlfnSiBWRMoUJLiipsmJKs2OHLHmYbz1\nltUL8PLL1peqJzlxwkpAUhOB77+3ejMqVrQSkNREoFMnqFDBnhj/+AO++eZSjD/8YCUx/v5Wj0pq\njEFBUK6cPTEqVRjsTk4OYM0tWZLdsI0xphzgFJGlBQmuqGlyopQ1r+KBB6wv/pAQaxVL3bpFH4cI\nHDrk2iuxe7f1We3aVo9I6hd9mzZWb4knOn3add5KZCScPw8+PnD11Zee4ZproHJlu6O13/nz1jyh\nw4ezfiUnuyaiLVpYw2rKfh4xrFMSaXKilCU5GZYutc7tOXsWnnjCOvm4fPnCu2dSknWQYfr5HL//\nbn3WsqXrEEmjRsV3iCQhwdp7Jn3SdeyY9QXbtq3rc9qRFBam5GTrWbNLPA4dsj5Pr3ZtqF//0ish\nweqZ2rHDaq96ddceqeBg7ZGyi909J6OAMyLyXoby2wHf4tZbkp4mJ0q5iouzltguXAgNGsBLL1mn\nIbsjMTh/Hr77znW+yKlT1ryXjh0vfdl06WINiZRUInDggGuycuCA9VnDhq49RJ7eS3DuXM69Hr/+\nau0rk8rX1zXxaNDA9X3dutknxKdPW718qclsZKR1f29va1gvfY9UlSpF8/ylnd3JyX5grIh8laG8\nB/BfEWlekIDspMmJUlnbu9da1fPpp3DTTVaS0qxZ3to4ftx1LkZUlPW34MqVrQQk9Uv4qqusIY/S\n7MgR19/Vjh1Wz1K1apl7CQqzNyu95GT466/MPR3p3x8/fqm+MZl7PTK+qlVzXw9YQoI1vyd9kvfX\nX1b7bdpcmhzdtStceaV77qlc2Z2cxAMtRCQ2Q3lDYK+IFNv/rWhyolT2RGDNGggNtYZbQkOtnWaz\n2t9DBA4edB2i2bfP+qxuXdfegMDA4rEyyE5nzli9BKm/y61breG28uWtXoLU32dBegnOnr18r0f6\nAyQrVMjc05Gx18PO4RUR+Pln12Rl/37rswYNXIfPWrXy7B6p4sLu5OQwMFFE1mYoHwC8IiLFNifV\n5ESpyzt/3tphds4ca3fV556DoUOtzc3SfxH8mTJdPjDQ9Yugfv3iO1/EUyQmws6d1u85NQE8etS1\nlyD1Va+e1etx5Ej2icfhw/D335fadzigTp2cez2qVCl+/x6PHr202mvLFmvPmqQk61nS90hddVXR\n9UiVJHYnJ88Cd2ItJ04d2umBtYLnfRF5pCAB2UmTE6Vy7/Bhayv8FSuseSIJCdbflK+66lIX+jXX\nFO9N3YoLEfjlF9fk8KefrM/8/a25Q+m33K9Y8fK9Hhl3yy2Jzp7N3CN15oyVmKT+d5w676lqVbuj\n9QxnzmTfw3bgwHZ+/92+5KQc8DZwO5CYUuwAlgH3isjF7K71dJqcKJV3X35pLTvu3NmayOqtx4F6\nhL/+snoJdu60DjNMn3z4+RW/Xo+ikJgIP/54KVnZssXqcYLMPYANGtgba2FISrp8D9uJE5fqZ+xh\nK1duO8uW2b9DbDOgHXAe2CUihwoSiCfQ5EQppVSq1LlT6Xuk9u61PqtXzzVZad3a8+dOnT6dc+Lx\n229WgpaqUqWce9jq1HHtYXPnsE6+ty0Skf1Yh/0ppZRSJY4x0Lix9Roxwio7dsx1l+L33rO+0P38\nXDeHK+pVZ0lJ1jyvnJKPf/65VN/Lyxq+S000unTJnHz4+RVd/Bnlq+ckZXv6/kB9rMP+0ojIZPeE\nVvS050QppVRenDuX+XynjPv1pJ7vVL16/u9z6tTlez2Ski7V9/PLvsejQQNrmbe7d1W2tefEGHM9\nsBaIAVoA0UBDwAAFCkYppZQqTnx9oUcP6wWXdjpOnbPyzjvw/PPWZ61auQ4FNWxo9c4kJrr2emTc\nP+bwYWtScyovL2uvltRkI3UVXOqrXj17ez3cIT950xzgBRF50hhzGhgM/AW8A3zizuCUUkqp4sTL\nC9q1s17335/1GVH//a9Vt3Ztq4fl999dez2qVLmUaHTvnrnno3Ztz5/fUlD5SU5aAs6UnxMBHxE5\nY4yZDqwBXnNXcEoppVRxZozVQ9KwIQwbZpWlnq797bfW5xl7PfQAyPwlJ2e5NM/kTyAASDkrlBJ8\nAoZSSilVcNWqwS23WC+VtfwkJ5FAV2Av8BHwojGmDTAo5TOllFJKqXzLT3IyGaiY8vOTKT/fCRxI\n+UwppZRSKt/ydNSRMcYLuBI4DCAiZ0XkXhFpKyKDC7IRmzHmfmPMQWPMeWNMpDHmqlzU32OMOWeM\n2WuMGZ5D3aHGmGRjzKr8xqeUUkqpopGn5EREkoCNgFtPGTDG3Am8iNUT0wHYCWwwxmQ5h8UYcx8w\nC5gOtAKeAl4xxvTLom5D4HkunQOklFJKKQ+Wn0Oio4HGbo4jFFgkIstEZB9wL3AOGJ1N/WEp9d8X\nkVgReRf4L/BY+krGGAcQhpXEHHRzzEoppZQqBPlJTv4FvGCMucUYU9sYUzn9K6+NGWPKAsHAptQy\nsbat/Qy4JpvLygPxGcrigU4pQ0+pngSOishbeY1LKaWUUvbIz4TYj1L+uRZIv/e9SXmf161h/FOu\nOZqh/CjQPJtrNgBjjTFrRGS7MaYjMAYom9LeUWNMV2AU1uGESimllCom8pOc9HJ7FHn3NFAT2Joy\ndHMEWAJMAZKNMRWBZcA4Efkn21ayERoail+GvX+dTidOpzObK5RSSqnSIyIigoiICJeyuPR77BdQ\nvg7+c6eUYZ1zwGARWZuufAngJyK35XCtF1aS8idwDzBXRKoYY9phnfOThNWjA5eGsJKA5iKSaQ6K\nHvynlFJK5Y/dB/91z+lzEcnTqhgRSTDGRAGpBwpijDEp7xde5tok4I+Ua4YC61I+2ge0yVB9Ftae\nLJOAX/MSo1JKKaWKTn6Gdb7Ioix990t+jiOaByxJSVK+w1q944s1VIMxZg5QR0TuTnnfFOgEbAOq\nYW3+1hoYASAiF4A96W9gjDlpfSR78xGfUkoppYpIfpKTjHuclMXam+Rp4In8BCEiK1L2NJmJNUzz\nA9BHRI6lVKkF1Et3iRfwMNAMSAA2A11E5HB+7q+UUkopz5Hn5EREsprx8qkx5iJWD0hwfgIRkVeB\nV7P5bFSG9/uAPE0KydiGUkoppTxTfvY5yU5OS3+VUkoppXIlPxNi22YsAmoDU7GGY5RSSiml8i0/\nc05+wJoAazKUR5L9dvNKKaWUUrmSn+SkUYb3ycAxEcm4nbxSSimlVJ7lZ0LsocIIRCmllFIK8jEh\n1hiz0BgzMYvyicaYl9wTllJKKaVKq/ys1hkMfJ1F+bfAkIKFo5RSSqnSLj/JSXXgdBblp7BOBFZK\nKaWUyrf8JCc/AzdlUX4TEFOwcJRSSilV2uVntc484D/GmCuAz1PKrsfaTv4hdwWmlFJKqdIpP6t1\nFhtjymOdo/PvlOJY4D4RWebG2JRSSilVCuWn5wQReQ14LaX35LyInHFvWEoppZQqrfKzfX0joIyI\nHEh3ajDGmKZAgojEujE+pZRSSpUy+ZkQuwS4Oovyq1M+U0oppZTKt/wkJx2ArVmURwLtCxaOUkop\npUq7/CQnAlTOotwP8CpYOEoppZQq7fKTnHwFPG6MSUtEUn5+nKx3jlVKKaWUyrX8rNZ5DCtB+ckY\nsyWlrBtWz0kvdwWmlFJKqdIpzz0nIrIHaAusAGoAlYBlQDP3hqaUUkqp0ii/+5z8AUwDMMZUBoYC\nnwAd0XknSimllCqA/Mw5AcAY090YsxT4A3gE2Ax0dldgSimllCqd8tRzYoypBYwExmCt2FkBlAcG\npgz3KKWUUkoVSK57Towx64CfsOabPATUEZEHCiswpZRSSpVOeek5uQlYCLwmIgcKKR6llFJKlXJ5\nmXPSFWtlTpQxZpsxZqIxxr+Q4lJKKaVUKZXr5EREIkVkHFAbWIS1QuePlDZuNMZUKpwQlVJKKVWa\n5Gefk7MislhEugJtgBeBqcBfxpi17g5QKaWUUqVLvpcSA4jITyIyBbgScLonJKWUUkqVZvnahC0j\nEUkCVqe8lFJKKaXyrUA9J0oppZRS7qbJiVJKKaU8iiYnSimllPIompwopZRSyqNocqKUUkopj6LJ\niVJKKaU8iiYnSimllPIompwopZRSyqO4ZRM2pZRSnuVC4gU+/vljNvy8gQtJF+wOx21qVqjJ7a1v\np0OtDhhj7A5HFRJNTpRSqoRISk5ic+xmInZFsHLvSuIuxNHCvwVVvavaHZrbrNu/jrnfzKV59eY4\nA5042zhpVr2Z3WEpN9PkRCmlijER4bvfvyMiOoJ3d7/LkTNHaFy1MQ90egBnGyetrmhld4hulZCU\nwKaDm4iIjuCFrS/w1JdPEVw7mJA2IdzZ+k7qVq5rd4jKDYyI2B2DxzDGBAFRUVFRBAUF2R2OUkpl\na8+xPYTvCiciOoKYf2KoVbEWQ1sPxdnGyVV1rioVQx7nE87z4YEPCd8VzocHPiQhKYEeDXsQEhjC\n4FaDqeZTze4QS5Xt27cTHBwMECwi2wvSlsckJ8aY+4FHgFrATuABEfn+MvXvBxoCh4DZIvJ2us/H\nAiOAwJSiKGDaZdrU5EQp5bEOnTzE8ujlhEeH8+PRH/Er78eQVkNwBjrp2bAnXg4vu0O0zcn4k3yw\n9wMioiPYdHATXsaLvk364gx00r95fyqUq2B3iCWeO5MTjxjWMcbcCbwIjAe+A0KBDcaYZiJyPIv6\n9wGzgLHA/4CrgTeMMSdE5MOUaj2AcOBbIB6YCmw0xrQSkT8L+5mUUsod/jr7F+/tfo+I6Ai++fUb\nfMr4cGvzW5nZcyZ9m/SlfJnydofoEap4V2FUh1GM6jCKI2eO8N7u9wiPDidkVQi+ZX0Z0HwAzkAn\nfZr0oZxXObvDVZfhET0nxphIYJuIPJjy3gC/AgtF5Lks6n8DfC0ij6UrewHoJCLds7mHA/gHuF9E\nwrKpoz0nSinbnbpwitX7VhO+K5zPYj7DGEPvgN44A50MaD6ASuUr2R1isRHzT4zV27QrnN3HdlPV\nuypDWg0hpE0I3Rt0x2F0Rw13KVE9J8aYskAwMDu1TETEGPMZcE02l5XH6g1JLx7oZIzxEpGkLK6p\nAJQFThQ8aqWUcq/4xHg+OvAREdERrN+/nvjEeLo36M5/bv4PQ1oNwd/X3+4Qi6XGVRszrds0pnWb\nxq6ju4iIjiB8VzhvbH+DOpXqMLT1UELahBBUO6hUzNMpLmxPTgB/wAs4mqH8KNA8m2s2AGONMWtE\nZLsxpiMwBiv58M+iLYBngd+Bz9wStVJKFVBiciKbD24mPDqcVXtXcerCKTrU6sDMnjMZGjiUen71\n7A6xRGlTsw1tarZh1nWziPwtkvBd4YTtCmNe5DyaVmtKSJsQnIFOmvtn99WjiortwzrGmNpYScM1\nIrItXfmzQHcRydR7YozxBv4DDMfa5fYIEAZMAWqJyLEM9adiTbbtISK7c4glCIjq3r07fn5+Lp85\nnU6cTmf+HlIppVKICJG/RaYt/f3r7F80rdY0bc+OFv4t7A6xVElMTuTzg58TER2RliAG1Q7CGehk\naOBQrqx8pd0heqSIiAgiIiJcyuLi4vjqq6+gJKzWSRnWOQcMFpG16cqXAH4iclsO13oBNYE/gXuA\nuSJSJUOdR4BpwPUisuMyseicE6VUoYj+K5rwXeEsj17OwZMH04YUnG2cBNcO1iEFD5A6tBa+K5z1\n+9dzMeki3Rp0IyQwhCGthlDdt7rdIXq0EjXnREQSjDFRwPXAWkibEHs9sPAy1yYBf6RcMxRYl/5z\nY8wU4HGg9+USE6WUcreD/xxMW/ob/Ve0y2TMbvW7leqlv57Iu4w3g1oOYlDLQcTFx7F632oioiO4\n/6P7mfjxRPoE9LEmJbcYQMVyFe0Ot0SzPTlJMQ9YkpKkpC4l9gWWABhj5gB1ROTulPdNgU7ANqAa\nMBlojbWvCSl1HgNmAE7gsDGmZspHZ0TkbBE8k1KqFDp65ijv7XmP8F3hbP1tK75lfenfvD+zr5ut\ny1iLET9vP+5ufzd3t787bTl3eHQ4wz4Yhk8ZH/o3709ImxD6BPTR5dyFwCOSExFZYYzxB2ZiDdP8\nAPRJN3ekFpB+ZpgX8DDQDEgANgNdRORwujr3Yk2QfT/D7Wak3EcppdwiLj6OD/ZZG4B9FvMZDuOg\nb5O+vDPoHfo3769/yy7malSowf2d7uf+TvcTezKW5dHLiYiOYMDyAVTxrsKQlkNwtnHSo0EP7Q1z\nE9vnnHgSnXOilMqt8wnnrfkJ0eF8uP9DLiZdpEfDHjgDnQxuOVjnJ5QCu//anbY0+eDJg9SuWJs7\nW99JSJsQOtbpWOrmEZXI7es9gSYnSqmcJCYnsilmU9rKjtMXT+uhcyrt8MXwXeG8u/tdjp49SpNq\nTawVWIFOWl7R0u4Qi4QmJ4VEkxOlVEYiwtbfthK+K5z39rzHX2f/oln1ZoQEhuBs46RZ9WZ2h6g8\nSFJyEptjNxOxK4KVe1cSdyGO9rXapy1Nru9X3+4QC40mJ4VEkxOlFFgJya6/dhGxK4KI6AgOxR2i\nbqW6aXuRdKjVodR12au8u5B4gY9//pjwXeGs27+O+MR4utbvmrY0+YoKV9gdoltpclJINDnxXOG7\nwkmWZD1XxMOcvnCa1ftW88ORH+wOxW0SkxPZdHATu4/tpppPNW5vdTshbULoWr+rnsOi8u30hdOs\n+WkN4bvC2fjLRgB6B/SmpX/JGfI5euAo7zzwDmhy4l6anHimH478QNCiIARJO5HVGejkpiY36RI+\nG2T1t8Gm1ZpSxuERi//cokPtDoQEhnBjwI269Fe53bGzx3h/z/us2LOCo2eyOm2leDr/63lin40F\nTU7cKzU5Wf/Fevr16Gd3OAqre73X0l78dfYv1jnXsXLvSiKiI/jhyA/4lfdjcMvBONs46dWwly7h\nK0TZjaOHBIZwZ+CdJXocXSmVOzqsU0hSk5M+z/Xhk0c/sTscBazau4rBKwbz8V0f07dJ37TyPcf2\npM0H+OWfX6hVsRZ3tr4TZ6CTTnU76XwAN0i/AmHFnhUcOXOkVK5AUErljiYnhSQ1OWE8fPOvb+hS\nr4vdIZVqFxIv0PKVlrTwb8FHd32UZR0R4fs/vidiVwTLdy/nyJkjNK7aGGegk5A2IbS6olURR138\npe7dEBEdQcw/MdSuWJuhgUNxBjpL5d4NSqnc0eSkkKQmJ82nNadyw8pEjo3UCXA2eu6b55i2aRrR\nE6JzdVJrUnISXx76kvBd4azcu5KT8SdpW7MtIYEhDA0cSoMqDYog6uIp/a6XPx79MW3Xy5A2IXRv\n0F1fIrMAAB8LSURBVF2HzJRSl6XJSSFJTU7eWP8G4/43jmUDlzG83XC7wyqVjp45StOXmzKq/SgW\n3LQgz9dfSLzAhl82EL4rnLU/reV84nmurXctzkAnt7e+nRoVahRC1MVL+vNCvv31Wz0vRClVIJqc\nFJL0q3Xm/jKXb379hp8m/qTnYthg3NpxrNq3igMPHKCaT7UCtXXm4hnW7FtDeLS1hE9EuKHxDYS0\nCWFgi4FULl/ZTVF7vlMXTvHB3ktnwBhj9KRVpZRbaHJSSNInJ1UbVaXlKy2Zcu0UZvbScwKL0o4/\ndxD832AW3rSQiZ0murXt4+eO8/6e94mIjuCrQ1/hXcabW5rdgjPQyc1Nb8a7jLdb7+cJ4hPjrTNg\ndoWzfv96LiRdoHuD7oQEhjC41WD8ff3tDlEpVQJoclJIMu5zMm3TNOZHzueniT/pUskikn7p8M57\nd1LWq2yh3evXuF95d/e7hO8KZ8eRHVQuX5lBLQcREhhCr0a9ivW+HYnJiXx+8PO0M2BOXThFUO0g\nnIFO7mx9J/X86l2+EaWUygNNTgpJxuTk9IXTNPtPM3o27EnE4Ai7wysV/r+9O4+vqrr6P/5ZWJBJ\nAScQBEVFBIIoCIKAKFFxqFqrgonz1NrHDkFlRu1PCgQUiFN/tvYpoDVB1FrxsZUKWGVGmSQyaWUe\nHFAxEBAk6/nj3PBc0wCZbs654ft+vc7rxT13n33WJpC77jl7nf3q8le5/uXreeumt+h1eq9KO+/K\nL1fuL03++KuPOaHOCftLkzuf1DkpKlTcnXkb5+0v/f185+e0OKYF6W3TSUtJo+VxLcMOUUSqMCUn\nCVLcE2LHLx7PnVPuZPadKi1OtN3f76b1M61pdXwr3kx/M5QY3J2FWxbuL03enLeZ5vWbc2PKjaS3\nTSflhJRQ4jqY3M9zyV6WTU5uDmu/WUvjoxpzY5sg3vYntk+KxEpEkp+SkwQpLjkp8AI6PteRalaN\n+XfPV2lxAo2aNYqh7wxl2S+Wlah0ONH2Fexj5vqZZC/L5pXlr/D17q9JOSFlf2ly8wbNQ4ttzddr\nmJQ7iezcbHI/z6VBzQbc0PoG0tqm0b1Zd5X+ikilU3KSIAdaW2fmuplcMOECJv5kIre2uzW8AKuw\nrTu20uKpFtx1zl1kXZYVdjj/Yc++PUz9ZCo5uTm8vup18vfm0+WkLqSlpNG7TW8a1m2Y8Bg+2/EZ\nkz+aTE5uDnM3zqV29dpc0/Ia0tumc+lpl2oNGBEJlZKTBDnYwn99XunDzHUzWf2r1Sq3TIC7p9zN\naytfq5DS4UTbuWcnU1ZNITs3m7c+eYsCLyC1eSrpbdO59sxrqVezXoWda/vu7fx1xV/Jyc1h+prp\nVLNqXH765aSlpHF1y6upU6NOhZ1LRKQ8lJwkyMGSk7XfrOXMp8+k3/n9GNZzWDgBVlGFpcNPXf4U\n93W6L+xwSmVb/rb9ixG+u/ZdahxRgyvPuJK0lDSubHEltarXKnWfu/bu4s2P3yQnN4c3V7/Jnn17\n6HFKD9JS0riu1XUcW/vYBIxERKR8lJwkyMGSE4Ah04cwdt5YVt63Uo9CryDuzoUTL+TL/C9Zeu/S\npC7f3fTtpv2lyQu3LOSoGkdxbatrSU9JJ/XU1IOO7fuC75n+6XSyc7N5bcVr5O3Jo8OJHUhvm06f\nNn1ocnSTShyJiEjpKTlJkEMlJzv27KDFUy3ocXIPJl0/qfIDrIIKS4en3jyVS0+7NOxwKszqbavJ\nWZZDdm42q7et5vjax9O7TW/S26bT5aQumBkFXsDcDXPJyc1h8keT+SL/C1oe2zJY9bdtGmcce0bY\nwxARKTElJwlyqOQEYMKSCdzx+h3MumMWXZt1rdwAq5jd3++m1TOtaHN8G/4n/X/CDich3J3FWxeT\nvSybSbmT2JS3iZPrnUzP5j2ZsWYG67avo8lRTfYnJOc0OkelvyKSlJScJEhJkpMCL6DTc50AWHDP\nApUWl0PmrEweeuchcn+Re1g8IKzAC5i5bmYwP2Xdu/Q4uQfpbdPp1qyb/h2JSNKryOQkeW/wh6Sa\nVSPrsiy6j+/OC0tf4Lazbws7pKS0JW8Lw2cO55cdf3lYJCYQ/NvpcUoPepzSI+xQREQiTV/XyqBb\ns270adOHQdMHsWPPjrDDSUpDZwzlyCOO5OEeD4cdioiIRIySkzIadfEovtr1FZmzMsMOJeks2rKI\n8UvG8+hFj9KgVoOwwxERkYhRclJGJ9c/mQfPf5DH5zzO2m/Whh1O0nB3Mt7KoPXxrflZh5+FHY6I\niESQkpNyGNhtIMfUOoYB0waEHUrSeHXFq8xcP5NxvcYl9TNNREQkcZSclEPdGnUZmTqSyR9NZtb6\nWWGHE3m7v99Nv7f78eMzfswlp10SdjgiIhJRSk7K6ZZ2t3Bu43PJeCuDAi8IO5xIGzd3HBu/3ciY\nS8eEHYqIiESYkpNyqmbVyOqVxcItC3l+6fNhhxNZhaXDv+r0Kz35VEREDkrJSQXo2qwrN6bcyKDp\ng8j7Li/scCJpyIwh1PxRTR664KGwQxERkYhTclJBMlMz+Wb3NyotLsbCzQuZsGQCwy4aptJhERE5\nJCUnFeTk+ifzYJcHGTN3DGu+XhN2OJHh7mRMzaDNCW24p8M9YYcjIiJJQMlJBRrQbQDH1j5WpcVx\nXln+CrPWz2LspWNVOiwiIiWi5KQCFZYWv7z8ZWaumxl2OKHbtXcX/d7ux1VnXKXSYRERKTElJxXs\n5rNupmPjjmRMVWnxuHnj2Jy3WaXDIiJSKkpOKljhqsWLtixi4pKJYYcTms15mxkxcwS/6vQrWhzb\nIuxwREQkiSg5SYDzm55PWkoag2cMPmxLi4fMGEKt6rV4qIdKh0VEpHSUnCRI5sVBafHIWSPDDqXS\nfbD5g/2lw/Vr1g87HBERSTKRSU7M7D4zW2Nmu8xsnpl1LEH75WaWb2YrzOyWYtrcEHtvl5ktNbPL\nEzeCH2pWrxn9zu/H2LljD6vS4sJVh1NOSOHu9neHHY6IiCShSCQnZtYHGAM8ApwDLAWmmtlxB2j/\nC2A48DDQGvgt8IyZXRnX5nwgG3gOOBt4HfibmbVO3Eh+aEDXoLS4/7T+lXXK0L28/GVmb5hNVq8s\nlQ6LiEiZRCI5AfoCf3D35919JXAvkA/ceYD2N8fav+Lua939JeCPQPwDRn4N/MPdx7r7Knd/GFgE\n/DJxw/ihOjXqkJmaySvLX+G9de9V1mlDU1g6fHXLq0k9NTXscEREJEmFnpyYWXWgAzC9cJ+7OzAN\n6HKAw44EdhfZtxvoZGZHxF53ifURb+pB+kyIm866iU5NOpHxVgb7CvZV5qkr3di5Y9mSt4XHL3k8\n7FBERCSJhZ6cAMcBRwCfFdn/GdDoAMdMBe42s/YAZnYucBdQPdYfsWNL02dCFK5avHjrYiYurbql\nxZvzNjNy1kh+fd6vVTosIiLlEoXkpCyGAf8A5prZXuA1YELsvcg9+axL0y6kt01n8PTBfPvdt2GH\nkxCDpw+mVvVaDL1gaNihiIhIkovCjMUvgX1AwyL7GwJbizvA3XcTXDn5eazdFuDnQJ67fxFrtrU0\nfcbr27cv9erV+8G+tLQ00tLSDnXoAWWmZtJyRUtGzhzJyIurVnnx+5veZ+LSiTx75bMqHRYROQzk\n5OSQk5Pzg33bt2+vsP4tmN4RLjObB8x399/EXhuwHnjS3R8rYR//Aja4+y2x15OAWu5+TVyb2cBS\nd/+vA/TRHli4cOFC2rdvX54hFeuRdx4hc3YmK+5bwakNTq3w/sPg7nQb34287/JY9PNFqtARETlM\nLVq0iA4dOgB0cPdF5ekrKrd1xgL3mNmtZnYm8CxQm9itGjMbaWb7J2yYWQszu8nMTjezTrFEpA0w\nJK7PJ4DLzOx+M2tpZr8lmHj7dOUM6T/179qf42sfT/+3q05p8eSPJjNnwxyyLlPpsIiIVIxIJCfu\nPhl4EHgUWAycBfSKu0XTCGgad8gRwAPAEoLJsTWA8919fVyfc4F04Gexdj8FrnH35YkdzYHVqVGH\nzIszeXXFq7y79t2wwqgwu/buov+0/lzT8hp6Nu8ZdjgiIlJFROarrrv/Hvj9Ad67o8jrlcAh77u4\n+6vAqxUSYAVJb5vO0wueJmNqBh/c8wFHVDvi0AdF1Ji5Y9iSt4Xpt04/dGMREZESisSVk8NJ4arF\nS7YuYcKSCWGHU2abvt3EyFkj+c15v+H0Y04POxwREalClJyEoPNJnbmp7U0MnpG8pcWDZwymTvU6\nKh0WEZEKp+QkJCNTR5L3XR4jZo4IO5RSW7BpAc8vfZ7f9fwd9WrWO/QBIiIipaDkJCRN6zWlf9f+\njJs3jn9/9e+wwymxwlWHz2p4Fnedc1fY4YiISBWk5CRE/bv254Q6JyTVqsUvffQSczfOJatXVlJP\n5hURkehSchKi2tVrk5mayV9X/JV/rf1X2OEcUv7efPq/3Z+fnPkTLmp+UdjhiIhIFaXkJGTpbdPp\nfFLnpFi1eMycMWzdsVWrDouISEIpOQmZmZHVK4ulny1l/JLxYYdzQJu+3UTm7EwyOmdw2jGnhR2O\niIhUYUpOIuC8k87j5rNuZsiMIZEtLR40fRB1qtdhSPchh24sIiJSDkpOIqKwtHj4e8PDDuU/zN84\nnxc+fIHhPYerdFhERBJOyUlEnHT0SQzoOoCs+VmRKi12dzKmZtCuYTvuPOfOsMMREZHDgJKTCOnX\ntR8n1DmBfm/3CzuU/SblTmLexnmM6zVOpcMiIlIplJxESO3qtRl18SheW/ka76x5J+xwgtLhaf25\n9sxrVTosIiKVRslJxKSlpAWlxVPDLy1+fM7jfL7zcx675LFQ4xARkcOLkpOIMTOeuOwJPvzsQ/68\n+M+hxbHx242Mmj2KjPNUOiwiIpVLyUkEdWrSiVvOuoUhM4awfff2UGIYNH0QdWvUZcgFKh0WEZHK\npeQkokakjmDn3p0Mn1n5pcXzNs7jLx/+heE9h3P0kUdX+vlFROTwpuQkovaXFs/L4pOvPqm08xau\nOtyuYTvuOPuOSjuviIhIISUnEfbg+Q/SqG6jSi0tzsnNYf6m+WRdplWHRUQkHEpOIqywtPhvK//G\njDUzEn6+nXt2MmDaAH7a6qdceMqFCT+fiIhIcZScRNyNKTfS5aQulbJqsUqHRUQkCpScRFxhafGy\nz5fxp0V/Sth5NmzfwKjZo+jbuS+nNjg1YecRERE5FCUnSaBjk47c2u5Whr4zNGGlxYOmD+LoI49m\ncPfBCelfRESkpJScJIkRPUeQvzef3733uwrve97Geby47EWVDouISCQoOUkSTY5uwsCuA3li/hN8\nvO3jCuu3wAvIeCuDsxudze1n315h/YqIiJSVkpMkkojS4pxlsdLhXiodFhGRaFBykkRqVa/F6EtG\n8/qq15n+6fRy91dYOnxdq+vocUqPCohQRESk/JScJJk+bfpwftPzyZiawfcF35err8fmPMYX+V+o\ndFhERCJFyUmSMTOyemWR+3luuUqLN2zfwOjZo7m/8/00b9C8AiMUEREpHyUnSahjk47c1u42Hnrn\nIb7Z/U2Z+hg4faBKh0VEJJKUnCSpEallLy2eu2Eu2cuyGZE6gqOOPCoB0YmIiJSdkpMk1fioxgzq\nNogn5z9ZqtLiAi8gY2oG5zQ6h9va3ZbACEVERMpGyUkSe6DLA5x41Ik8+PaDJT4me1k2CzYt0KrD\nIiISWUpOklit6rUYffFopqyawrRPpx2y/c49Oxk4bSDXt76eC06+oBIiFBERKT0lJ0mud5vedG3a\nlb5T+x6ytHj07NF8mf8loy8eXUnRiYiIlJ6SkyRnZmRdFpQWP7fwuQO2W799PaPnjOb+LiodFhGR\naFNyUgWc2/hcbj/79oOWFg+cNpD6NeszqNugSo5ORESkdJScVBHDew5n9/e7GfbusP94b86GOeTk\n5jCip0qHRUQk+pScVBH7S4sXPMnqbav37y9cdbj9ie257WyVDouISPQpOalC7u9yP02OasKD//y/\n0uIXP3yR9ze/T1avLKqZftwiIhJ9+rSqQgpXLX5j9Ru8/e+3Gf/CeAZOH8gNrW+g+8ndww6v3HJy\ncsIOoUJVpfFUpbFA1RpPVRoLaDyHi8gkJ2Z2n5mtMbNdZjbPzDoeov1NZrbEzHaa2WYz+28zO6ZI\nmwwzW2lm+Wa23szGmtmRiR1JuG5ofQPdmnWj79S+jPj/I9iWv43Rl1SN0uGq9p+4Ko2nKo0FqtZ4\nqtJYQOM5XEQiOTGzPsAY4BHgHGApMNXMjjtA+67AROA5oDVwPdAJ+GNcm3RgZKzPM4E7gd7A8IQN\nJAIKVy1e/sVyPtn2CQ90eYBT6p8SdlgiIiIlFonkBOgL/MHdn3f3lcC9QD5BQlGczsAad3/G3de5\n+xzgDwQJSqEuwCx3f8nd17v7NGBSkTZVUofGHbin/T3UrF6TQd1VOiwiIskl9OTEzKoDHYDphfvc\n3YFpBAlGceYCTc3s8lgfDYEbgDfj2swBOhTeHjKzU4ErirSpsp798bP0PKUndWvUDTsUERGRUvlR\n2AEAxwFHAJ8V2f8Z0LK4A9x9jpndDLxkZjUJxjEF+GVcm5zYbaFZZmaxczzr7qMOEktNgBUrVpR1\nLJGyI28HixYtCjuMCrN9+3aNJ6Kq0ligao2nKo0FNJ4oi/vsrFnuztw91A04ESgAziuyfxQw9wDH\ntAY2AfcDKcAlBPNU/hTX5kJgC3AH0Aa4BlgHDD1ILOmAa9OmTZs2bdrKvKWXNzew2IdyaGK3dfKB\n69x9Stz+CUA9d7+2mGOeB2q6e++4fV2BmcCJ7v6Zmb0HzHP3/nFtbiKY21LsvQ4zOxboBawFdlfA\n8ERERA4XNYFTgKnuvq08HYV+W8fd95rZQiCV4NYMsdswqcCTBzisNrCnyL4CgozN4toUXaa3oLB/\nLyYri/1lZpdhGCIiIhLM9yy30JOTmLHAhFiSsoCgeqc2MAHAzEYCjd39tlj7N4A/mtm9wFSgMTAO\nmO/uW+Pa9DWzpcB8oAXwKDCluMREREREoiESyYm7T45NXn0UaAgsAXq5+xexJo2ApnHtJ5pZXeA+\n4HHgG4Jqn4Fx3Q4juFIyDGgCfEFwZWZoYkcjIiIi5RH6nBMRERGReKE/50REREQknpITERERiRQl\nJ4CZdTezKWa2ycwKzOzqsGMqKzMbZGYLzOxbM/vMzF4zszPCjqsszOxeM1tqZttj2xwzuyzsuCqK\nmQ2M/XsbG3YsZWFmj8Tij9+Whx1XWZlZYzN7wcy+jC0WutTM2ocdV1nEFlEt+rMpMLOnwo6tLMys\nmpkNM7NPYz+bT8wsaecPmlldM8sys7Wx8cwys3PDjqskSvJ5aWaPxhbkzTezt83s9NKeR8lJoA7B\nJNz/IihHTmbdgaeA84CLgerAP82sVqhRlc0GYADQnmCJgxnA62bWKtSoKkBsWYWfETw8MJnlEkxi\nbxTbuoUbTtmYWX1gNvAdwbOOWgEPAF+HGVc5nMv//UwaETyo0oHJYQZVDgOBnxP8jj4T6A/0N7Nf\nHvSo6Ppvgsdl3ETwING3gWlmdmKoUZXMQT8vzWwAwdPaf0awlt1OgoV8a5TmJJoQW4SZFQA/iX8g\nXDKLVUF9Dlzg7rPCjqe8zGwb8KC7jw87lrKKVZotBH4BPAQsdvf7w42q9MzsEeAad0/KqwvxzCwT\n6OLuPcKOJRHMLAu4wt2T9SrqG8BWd78nbt8rQL673xpeZKUXW3IlD7jK3d+K2/8B8Hd3fzi04Eqp\nuM9LM9sMPObu42KvjyZYjuY2dy9xcqwrJ1VffYLs9quwAymP2GXdGwmefzM37HjK6RngDXefEXYg\nFaBF7PLuv83sL2bW9NCHRNJVwAdmNjl2O3SRmd0ddlAVIfYU7psIvq0nqzlAqpm1ADCzdkBX4O+h\nRlU2PyJY6+27Ivt3kaRXHguZWXOCK3XxC/l+S/CssQMt5FusSDznRBIj9qTdLGCWuyflXAAzSyFI\nRgq/bVzr7ivDjarsYgnW2QSX3ZPdPOB2YBXBGlm/Bd4zsxR33xliXGVxKsGVrDHAcILL0U+a2Xfu\n/kKokZXftUA9YGLYgZRDJnA0sNLM9hF8sR7i7pPCDav03H2Hmc0FHjKzlQRXFdIJPrw/DjW48mtE\n8GW4uIV8G5WmIyUnVdvvCRZJ7Bp2IOWwEmhH8Mv1euB5M7sgGRMUMzuJIFm82N33hh1Pebn71LiX\nuWa2gGBxzd5Ast12qwYscPeHYq+XxhLje4FkT07uBP4R9/TsZNSH4AP8RmA5QYL/hJltTtLk8Wbg\nzwQL2H4PLCJYOqVDmEFFiW7rVFFm9jRwBXChu28JO56ycvfv3f1Td1/s7kMIJpD+Juy4yqgDcDyw\nyMz2mtleoAfwGzPbE7vSlbTcfTuwGij1zPwI2AKsKLJvBdAshFgqjJk1I5gY/1zYsZTTaCDT3V92\n94/c/UWCJUsGhRxXmbj7Gne/iGByaVN37wzUAD4NN7Jy20qwvl3DIvsbxt4rMSUnVVAsMbkGuMjd\n14cdTwWrBhwZdhBlNA1oS/Ctr11s+wD4C9Au2dd8ik30PZ3ggz7ZzAZaFtnXkuBKUDK7k+CSejLO\nzYhXG9hXZF8BSf4Z5u673P0zM2tAUCX2t7BjKg93X0OQhKQW7otNiD2PUi4IqNs6gJnVIfilWvjN\n9dTYhKuv3H1DeJGVnpn9HkgDrgZ2mllhBrvd3XeHF1npmdkI4B/AeuAogkl9PYBLw4yrrGLzMH4w\n98fMdgLb3L3ot/bIM7PHCBbYXEewftX/A/YCOWHGVUbjgNlmNoig3PY84G7gnoMeFWGxK3G3AxPc\nvSDkcMrrDWComW0EPiJ4vEBf4E+hRlVGZnYpwefNKoJFaUcT/G6YEGJYJVKCz8ssgp/VJ8BagvXt\nNgKvl+pE7n7YbwQfeAUEmXn89uewYyvDWIobxz7g1rBjK8NY/kRwmXMXQTb+T6Bn2HFV8BhnAGPD\njqOMsefEfunsIkggs4HmYcdVjvFcAXwI5BN8AN4ZdkzlHM8lsf/7p4cdSwWMpQ7B6vVrCJ6b8TFB\nMvyjsGMr43huAD6J/d/ZBDwBHBV2XCWM/ZCflwST4zfH/i9NLcu/QT3nRERERCIlqe/XiYiISNWj\n5EREREQiRcmJiIiIRIqSExEREYkUJSciIiISKUpOREREJFKUnIiIiEikKDkRERGRSFFyIiIiIpGi\n5EREIsHM3jGzsaU8psDMrj7I+z1ibY4uf4QiUlm08J+IRMW1BAsHVjSt0SGSZJSciEgkuPs3YcdQ\nUmZW3d0TkUiJCLqtIyIxsdsqT5jZKDPbZmZbzOyREh5bYGZ3mdlfzWynma02s6uKtEkxs7+bWZ6Z\nbTWz583s2CLnHxv3upGZvWlm+Wb2iZn1NrM1ZvbrIqc//mDnjelmZkvNbJeZzTWzNkViu87Mcs1s\nd+wc9xd5f42ZDTWziWa2HfiDmVU3s6fNbHOs3zVmNqAkf18icnBKTkQk3q3ADqAT0B942MxSS3js\nw8AkoC3wd+BFM6sPYGb1gOnAQqA90As4AZh8kP5eABoBFwDXA78Aji/NeWMMGA30Bc4FvgCmmNkR\nsdg6AC8B2UAK8AgwzMxuLXKeB4AlwNnAMODXwI9jsZ0B3ASsPch4RKSEzF23Y0UkuHIBVHP3HnH7\n5gPT3X3wIY4tAB5199/GXtcmSHIuc/d/mtkQoJu7Xx53zEnAeuAMd/8kdv7F7n6/mZ0JLAc6uPvi\nWPvTgI+BDHd/soTn7QG8A/R291dibRoAG4Hb3P0VM/sLcJy7XxYX2yjgCndvG3u9Bljo7tfHtXkC\naO3ul5T8b1lESkJXTkQk3odFXm8huMJREssK/+Du+cC3cce2A3rGbunkmVkesIJgsuppxfR1BrC3\nMDGJ9flv4OtSnpfYOebFtfkaWAW0iu1qBcwu0udsoIWZWdy+hUXaTADOMbNVsdthSlJEKogmxIpI\nvKKTPJ2Sf4k52LF1gSkEt4qsSLstpQmwlOetSDt/cBL3xWZ2CnA5cDEw2czedvfeCTi3yGFFV05E\npDIsAtoA69z90yLbrmLarwJ+ZGbnFO4ws9OBBmU4twGd4/ppQHBlZnls1wqga5FjugGr/RD3vd19\nh7u/7O4/B/oA1xWZ7yIiZaDkREQqwzPAMcAkMzvXzE41s15m9ucit04AcPdVBBNonzOzjrEk5Q9A\nPmV7bsnDZtbTzFIIbsd8Abwee28MkBqrxmlhZrcB9wGPHaxDM+trZjeaWUszOwPoDWxNppJokahS\nciIihcozO764Y/fvc/ctBFcnqgFTCea2jAW+jrs6UbSPW4CtwLvAq8BzBJNdd5f0vHGvBwJPAO8T\nVPxc5e7fx2JbTJBY9CGYv/JbYKi7v3CI8+QR3KZ6H5gPNAOuKKadiJSSqnVEJCnEVfekuvs7Yccj\nIomj5EREIsnMLiKYSLsMaEzwrJJGQEt33xdmbCKSWLqtIyIHZWbp8SXARbZlh+6hzKoDI4Bcgts6\nW4GLlJiIVH26ciIiB2VmdYCGB3h7r7tvqMx4RKTqU3IiIiIikaLbOiIiIhIpSk5EREQkUpSciIiI\nSKQoOREREZFIUXIiIiIikaLkRERERCJFyYmIiIhEyv8Ca81/HpqUJ9oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb5f1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10.\n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(train_feature, train_class)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(knn.score(train_feature, train_class))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(knn.score(test_feature, test_class))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the training and test set accuracy on the y-axis against the setting of n_neighbors on the x-axis. While real-world plots are rarely very smooth, we can still recognize some of the characteristics of overfitting and underfitting. Considering a single nearest neighbor, the prediction on the training set is perfect. But when more neighbors are considered, the model becomes simpler and the training accuracy drops. The test set accuracy for using a single neighbor is lower than when using more neighbors, indicating that using the single nearest neighbor leads to a model that is too complex. On the other hand, when considering 10 neighbors, the model is too simple and performance is even worse. (It is not a typo. Yes, using less neighbors leads to more complex models. Think carefully about this.) The best performance is somewhere in the middle, using around six neighbors. Still, it is good to keep the scale of the plot in mind. The worst performance is around 88% accuracy, which might still be acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear support vector machines (linear SVMs) is implemented in svm.LinearSVC. Let's apply it on the brest cancer dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "\n",
    "linearsvm = LinearSVC(random_state=0).fit(train_feature, train_class)\n",
    "print(\"Test set score: {:.3f}\".format(linearsvm.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are also implemented in scikit-learn. Since the features in the breast cancer dataset are all continuous numeric attributes, let's use GaussianNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "\n",
    "nb = GaussianNB().fit(train_feature, train_class)\n",
    "print(\"Test set score: {:.3f}\".format(nb.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are also implmented in scikit-learn. Let's use DecisionTreeClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "uuid": "6e5d7a76-9bba-42f7-b26e-907775d289b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(train_feature, train_class)\n",
    "print(\"Training set score: {:.3f}\".format(tree.score(train_feature, train_class)))\n",
    "print(\"Test set score: {:.3f}\".format(tree.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don’t restrict the depth of a decision tree, the tree can become arbitrarily deep and complex. Unpruned trees are therefore prone to overfitting and not generalizing well to new data. Now let’s apply pre-pruning to the tree, which will stop developing the tree before we perfectly fit to the training data. One option is to stop building the tree after a certain depth has been reached. In the above code, we didn't set max_depth (i.e., max_depth= None,  which is the default value). Nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split instances (min_samples_split is another parameter in DecisionTreeClassifier). Now let's set max_depth=4, meaning only four consecutive questions can be asked. Limiting the depth of the tree decreases overfitting. This leads to a lower accuracy on the training set, but an improvement on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.988\n",
      "Test set score: 0.951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(train_feature, train_class)\n",
    "print(\"Training set score: {:.3f}\".format(tree.score(train_feature, train_class)))\n",
    "print(\"Test set score: {:.3f}\".format(tree.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the tree using the export_graphviz function from the tree module. This writes a file in the .dot file format, which is a text file format for storing graphs. We set an option to color the nodes to reflect the majority class in each node and pass the class and features names so the tree can be properly labeled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names, impurity=False, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"1036pt\" height=\"477pt\"\r\n",
       " viewBox=\"0.00 0.00 1036.00 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-473 1032,-473 1032,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.403922\" stroke=\"black\" points=\"638,-469 491,-469 491,-401 638,-401 638,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"564.5\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">worst radius &lt;= 16.795</text>\r\n",
       "<text text-anchor=\"middle\" x=\"564.5\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 426</text>\r\n",
       "<text text-anchor=\"middle\" x=\"564.5\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [159, 267]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"564.5\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.901961\" stroke=\"black\" points=\"565.5,-365 367.5,-365 367.5,-297 565.5,-297 565.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">worst concave points &lt;= 0.1359</text>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 284</text>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [25, 259]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M532.682,-400.884C524.039,-391.887 514.578,-382.041 505.583,-372.678\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"507.946,-370.086 498.494,-365.299 502.898,-374.935 507.946,-370.086\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"497.994\" y=\"-386.594\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.941176\" stroke=\"black\" points=\"736.5,-365 590.5,-365 590.5,-297 736.5,-297 736.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">texture error &lt;= 0.4732</text>\r\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 142</text>\r\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [134, 8]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>0&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M596.642,-400.884C605.374,-391.887 614.931,-382.041 624.018,-372.678\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"626.727,-374.913 631.18,-365.299 621.704,-370.038 626.727,-374.913\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"631.553\" y=\"-386.597\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.984314\" stroke=\"black\" points=\"358,-261 215,-261 215,-193 358,-193 358,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">radius error &lt;= 1.0475</text>\r\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 252</text>\r\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [4, 248]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M408.059,-296.884C390.838,-287.125 371.852,-276.366 354.106,-266.31\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.381,-263.01 344.955,-261.125 351.93,-269.1 355.381,-263.01\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.474510\" stroke=\"black\" points=\"538.5,-261 394.5,-261 394.5,-193 538.5,-193 538.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">worst texture &lt;= 25.62</text>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 32</text>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [21, 11]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"466.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>1&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M466.5,-296.884C466.5,-288.778 466.5,-279.982 466.5,-271.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"470,-271.299 466.5,-261.299 463,-271.299 470,-271.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.988235\" stroke=\"black\" points=\"211.5,-157 35.5,-157 35.5,-89 211.5,-89 211.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">smoothness error &lt;= 0.0033</text>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 251</text>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 248]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.579,-192.884C218.127,-183.214 201.106,-172.563 185.164,-162.587\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.768,-159.462 176.435,-157.125 183.055,-165.396 186.768,-159.462\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"343,-149.5 230,-149.5 230,-96.5 343,-96.5 343,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"286.5\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.5,-192.884C286.5,-182.326 286.5,-170.597 286.5,-159.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290,-159.52 286.5,-149.52 283,-159.52 290,-159.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" points=\"97,-53 0,-53 0,-0 97,-0 97,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"48.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 4</text>\r\n",
       "<text text-anchor=\"middle\" x=\"48.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"48.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.2686,-88.9485C90.1535,-79.9834 82.4418,-70.2666 75.296,-61.2629\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"77.8841,-58.8938 68.926,-53.2367 72.4011,-63.2454 77.8841,-58.8938\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.992157\" stroke=\"black\" points=\"219.5,-53 115.5,-53 115.5,-0 219.5,-0 219.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"167.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 247</text>\r\n",
       "<text text-anchor=\"middle\" x=\"167.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [2, 245]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"167.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.889,-88.9485C142.893,-80.3494 147.219,-71.0586 151.265,-62.3689\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.469,-63.7796 155.517,-53.2367 148.123,-60.8249 154.469,-63.7796\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" points=\"541.5,-157 361.5,-157 361.5,-89 541.5,-89 541.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"451.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">worst smoothness &lt;= 0.1786</text>\r\n",
       "<text text-anchor=\"middle\" x=\"451.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"451.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"451.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M461.63,-192.884C460.438,-184.778 459.144,-175.982 457.893,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"461.315,-166.684 456.397,-157.299 454.389,-167.702 461.315,-166.684\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.890196\" stroke=\"black\" points=\"727.5,-157 559.5,-157 559.5,-89 727.5,-89 727.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"643.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">worst symmetry &lt;= 0.2682</text>\r\n",
       "<text text-anchor=\"middle\" x=\"643.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 20</text>\r\n",
       "<text text-anchor=\"middle\" x=\"643.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [18, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"643.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>7&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M523.967,-192.884C540.901,-183.125 559.57,-172.366 577.02,-162.31\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"579.102,-165.15 586.019,-157.125 575.607,-159.085 579.102,-165.15\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.890196\" stroke=\"black\" points=\"378,-53 281,-53 281,-0 378,-0 378,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 9]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M408.83,-88.9485C396.548,-79.4346 383.172,-69.074 370.964,-59.6175\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"372.775,-56.5934 362.726,-53.2367 368.489,-62.1274 372.775,-56.5934\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"509,-53 396,-53 396,-0 509,-0 509,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [2, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M451.85,-88.9485C451.937,-80.7153 452.031,-71.848 452.119,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"455.622,-63.2732 452.228,-53.2367 448.622,-63.1991 455.622,-63.2732\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.498039\" stroke=\"black\" points=\"624,-53 527,-53 527,-0 624,-0 624,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"575.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"575.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 2]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"575.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M619.717,-88.9485C613.332,-80.0749 606.416,-70.4648 599.993,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"602.701,-59.3094 594.02,-53.2367 597.019,-63.398 602.701,-59.3094\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"755,-53 642,-53 642,-0 755,-0 755,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"698.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 17</text>\r\n",
       "<text text-anchor=\"middle\" x=\"698.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [17, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"698.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>11&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M662.736,-88.9485C667.794,-80.2579 673.264,-70.8608 678.367,-62.0917\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"681.516,-63.6401 683.521,-53.2367 675.466,-60.1189 681.516,-63.6401\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<polygon fill=\"#399de5\" stroke=\"black\" points=\"712,-253.5 615,-253.5 615,-200.5 712,-200.5 712,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>14&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M663.5,-296.884C663.5,-286.326 663.5,-274.597 663.5,-263.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"667,-263.52 663.5,-253.52 660,-263.52 667,-263.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.976471\" stroke=\"black\" points=\"905,-261 738,-261 738,-193 905,-193 905,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">worst concavity &lt;= 0.1907</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 137</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [134, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>14&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M714.798,-296.884C729.776,-287.214 746.274,-276.563 761.728,-266.587\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"763.686,-269.489 770.189,-261.125 759.889,-263.608 763.686,-269.489\"/>\r\n",
       "</g>\r\n",
       "<!-- 17 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\r\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.333333\" stroke=\"black\" points=\"897,-157 746,-157 746,-89 897,-89 897,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">worst texture &lt;= 30.975</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [2, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 16&#45;&gt;17 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>16&#45;&gt;17</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M821.5,-192.884C821.5,-184.778 821.5,-175.982 821.5,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"825,-167.299 821.5,-157.299 818,-167.299 825,-167.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 20 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>20</title>\r\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"1028,-149.5 915,-149.5 915,-96.5 1028,-96.5 1028,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"971.5\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 132</text>\r\n",
       "<text text-anchor=\"middle\" x=\"971.5\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [132, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"971.5\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 16&#45;&gt;20 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>16&#45;&gt;20</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M870.201,-192.884C887.991,-180.786 908.043,-167.151 925.583,-155.224\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"927.67,-158.037 933.971,-149.52 923.733,-152.249 927.67,-158.037\"/>\r\n",
       "</g>\r\n",
       "<!-- 18 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\r\n",
       "<polygon fill=\"#399de5\" stroke=\"black\" points=\"870,-53 773,-53 773,-0 870,-0 870,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 3]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"821.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = benign</text>\r\n",
       "</g>\r\n",
       "<!-- 17&#45;&gt;18 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>17&#45;&gt;18</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M821.5,-88.9485C821.5,-80.7153 821.5,-71.848 821.5,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"825,-63.2367 821.5,-53.2367 818,-63.2367 825,-63.2367\"/>\r\n",
       "</g>\r\n",
       "<!-- 19 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>19</title>\r\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"1001,-53 888,-53 888,-0 1001,-0 1001,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"944.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"944.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [2, 0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"944.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = malignant</text>\r\n",
       "</g>\r\n",
       "<!-- 17&#45;&gt;19 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>17&#45;&gt;19</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M864.519,-88.9485C877.022,-79.3431 890.647,-68.8747 903.051,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"905.204,-62.1046 911.001,-53.2367 900.939,-56.5537 905.204,-62.1046\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0xb5c2ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance in trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at the whole tree, there are some useful properties that we can derive to summarize the workings of the tree. The most commonly used summary is feature importance, which rates how important each feature is for the decision a tree makes. It is a number between 0 and 1 for each feature, where 0 means “not used at all” and 1 means “perfectly predicts the target.” The feature importances always sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "uuid": "dc2f68ee-0df0-47ed-b500-7ec99d5a0a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.01019737  0.04839825  0.          0.\n",
      "  0.0024156   0.          0.          0.          0.          0.\n",
      "  0.72682851  0.0458159   0.          0.          0.0141577   0.          0.018188\n",
      "  0.1221132   0.01188548  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our supervised models, so far we have split our dataset into a training set and a test set using the train_test_split function, built a model on the training set by calling the fit method, and evaluated it on the test set using the score method, which for classification computes the fraction of correctly classified samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn has its own function for producing confusion matrix. But, let's use pandas which is a popular Python package for data analysis. Its crosstab function produces a better-looking confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.988\n",
      "Test set score: 0.951\n",
      "Confusion matrix:\n",
      "Predicted   0   1  All\n",
      "True                  \n",
      "0          49   4   53\n",
      "1           3  87   90\n",
      "All        52  91  143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(train_feature, train_class)\n",
    "print(\"Training set score: {:.3f}\".format(tree.score(train_feature, train_class)))\n",
    "print(\"Test set score: {:.3f}\".format(tree.score(test_feature, test_class)))\n",
    "\n",
    "prediction = tree.predict(test_feature)\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(test_class, prediction, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we split our data into training and test sets is that we are interested in measuring how well our model generalizes to new, previously unseen data. We are not interested in how well our model fit the training set, but rather in how well it can make predictions for data that was not observed during training.\n",
    " \n",
    "Cross-validation is a statistical method of evaluating generalization performance that is more stable and thorough than using a split into a training and a test set. Cross-validation is implemented in scikit-learn using the cross_val_score function from the model_selection module. The parameters of the cross_val_score function are the model we want to evaluate, the training data, and the ground-truth labels. Let’s evaluate DecisionTreeClassifier on the breast cancer dataset. We can control the number of folds used by setting the cv parameter. We also summarize the cross-validation accuracy by computing the mean accuracy of the multiple folds. \n",
    "\n",
    "scikit-learn uses stratified k-fold cross-validation for classification. In stratified cross-validation, we split the data such that the proportions between classes are the same in each fold as they are in the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 0.92173913  0.88695652  0.9380531   0.92920354  0.90265487]\n",
      "Average cross-validation score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "scores = cross_val_score(tree, cancer.data, cancer.target, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, your task is to classify NBA players into 5 positions on the basketball court: SG (shooting guard), PG (point guard), SF (small forward), PF (power forward), and C (center). You make the classification based on the players' per-game average performance in the 2015-2016 season. The dataset is in a CSV file \"NBAstats.csv\" that is provided to you. For loading CSV file and processing the data, we suggest you to use pandas. A sample program is provided to you, as follows. Make sure to read the comments in the code, which will help you understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PS/G']\n",
      "         Player Pos  Age   Tm   G  GS    MP   FG  FGA    FG%  ...     FT%  \\\n",
      "0    Quincy Acy  PF   25  SAC  59  29  14.8  2.0  3.6  0.556  ...   0.735   \n",
      "1  Jordan Adams  SG   21  MEM   2   0   7.5  1.0  3.0  0.333  ...   0.600   \n",
      "2  Steven Adams   C   22  OKC  80  80  25.2  3.3  5.3  0.613  ...   0.582   \n",
      "\n",
      "   ORB  DRB  TRB  AST  STL  BLK  TOV   PF  PS/G  \n",
      "0  1.1  2.1  3.2  0.5  0.5  0.4  0.5  1.7   5.2  \n",
      "1  0.0  1.0  1.0  1.5  1.5  0.0  1.0  1.0   3.5  \n",
      "2  2.7  3.9  6.7  0.8  0.5  1.1  1.1  2.8   8.0  \n",
      "\n",
      "[3 rows x 29 columns]\n",
      "   Age   G  GS    MP   FG  FGA    FG%   3P  3PA    3P%  ...     FT%  ORB  DRB  \\\n",
      "0   25  59  29  14.8  2.0  3.6  0.556  0.3  0.8  0.388  ...   0.735  1.1  2.1   \n",
      "1   21   2   0   7.5  1.0  3.0  0.333  0.0  0.5  0.000  ...   0.600  0.0  1.0   \n",
      "2   22  80  80  25.2  3.3  5.3  0.613  0.0  0.0  0.000  ...   0.582  2.7  3.9   \n",
      "\n",
      "   TRB  AST  STL  BLK  TOV   PF  PS/G  \n",
      "0  3.2  0.5  0.5  0.4  0.5  1.7   5.2  \n",
      "1  1.0  1.5  1.5  0.0  1.0  1.0   3.5  \n",
      "2  6.7  0.8  0.5  1.1  1.1  2.8   8.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "['PF', 'SG', 'C']\n",
      "Test set predictions:\n",
      "['SF' 'C' 'PG' 'SF' 'PG' 'PF' 'PF' 'PG' 'C' 'C' 'C' 'PG' 'PG' 'PF' 'C' 'PF'\n",
      " 'SF' 'SF' 'SF' 'PF' 'C' 'PF' 'C' 'SF' 'C' 'PG' 'SF' 'PG' 'SG' 'PG' 'PF'\n",
      " 'SF' 'PG' 'SF' 'PF' 'SF' 'PF' 'PF' 'SF' 'PF' 'SF' 'SF' 'SF' 'PF' 'SG' 'SF'\n",
      " 'SG' 'C' 'PF' 'PF' 'PF' 'SF' 'PF' 'PF' 'PF' 'PG' 'SF' 'PG' 'PG' 'PF' 'SF'\n",
      " 'SF' 'PF' 'PF' 'SF' 'PG' 'PG' 'C' 'PG' 'SG' 'SF' 'PF' 'SF' 'SG' 'SG' 'SF'\n",
      " 'PG' 'C' 'PG' 'PG' 'PF' 'SF' 'C' 'PF' 'SG' 'SF' 'PF' 'SF' 'C' 'C' 'PF'\n",
      " 'SG' 'SG' 'SG' 'SG' 'PG' 'C' 'PF' 'SG' 'PG' 'PF' 'SF' 'C' 'C' 'SG' 'PF'\n",
      " 'PF' 'PG' 'PF' 'PF' 'C' 'SF' 'SF' 'C' 'PF' 'PF' 'PG' 'C' 'SF']\n",
      "Test set accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#read from the csv file and return a Pandas DataFrame.\n",
    "nba = pd.read_csv('NBAstats.csv')\n",
    "\n",
    "# print the column names\n",
    "original_headers = list(nba.columns.values)\n",
    "print(original_headers)\n",
    "\n",
    "#print the first three rows.\n",
    "print(nba[0:3])\n",
    "\n",
    "# \"Position (pos)\" is the class attribute we are predicting. \n",
    "class_column = 'Pos'\n",
    "\n",
    "#The dataset contains attributes such as player name and team name. \n",
    "#We know that they are not useful for classification and thus do not \n",
    "#include them as features. \n",
    "feature_columns = ['Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', \\\n",
    "    '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', \\\n",
    "    'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PS/G']\n",
    "\n",
    "#Pandas DataFrame allows you to select columns. \n",
    "#We use column selection to split the data into features and class. \n",
    "nba_feature = nba[feature_columns]\n",
    "nba_class = nba[class_column]\n",
    "\n",
    "print(nba_feature[0:3])\n",
    "print(list(nba_class[0:3]))\n",
    "\n",
    "train_feature, test_feature, train_class, test_class = \\\n",
    "    train_test_split(nba_feature, nba_class, stratify=nba_class, \\\n",
    "    train_size=0.75, test_size=0.25)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=1)\n",
    "knn.fit(train_feature, train_class)\n",
    "prediction = knn.predict(test_feature)\n",
    "print(\"Test set predictions:\\n{}\".format(prediction))\n",
    "print(\"Test set accuracy: {:.2f}\".format(knn.score(test_feature, test_class)))\n",
    "\n",
    "train_class_df = pd.DataFrame(train_class,columns=[class_column])     \n",
    "train_data_df = pd.merge(train_class_df, train_feature, left_index=True, right_index=True)\n",
    "train_data_df.to_csv('train_data.csv', index=False)\n",
    "\n",
    "temp_df = pd.DataFrame(test_class,columns=[class_column])\n",
    "temp_df['Predicted Pos']=pd.Series(prediction, index=temp_df.index)\n",
    "test_data_df = pd.merge(temp_df, test_feature, left_index=True, right_index=True)\n",
    "test_data_df.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the program above, we use 75% of the data for training and the rest for testing. Note that we are not setting random_state to a fixed value, since this is \"production code\". We built a k nearest neighbor classifier. Also note that we used two more parameters: metric for designating the distance function and p is the exponent in the Minkowski distance function. We used p=1 which means we used the Manhattan distance.\n",
    "\n",
    "To make it easier to understand the constructed classification model, we save the training set into a CSV file and the test set together with the predicted labels into another CSV file. You can look into the CSV files using Microsoft Excel to understand what mistakes were made by the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Tasks\n",
    "\n",
    "Your tasks are as follows. In your code, make sure randome_state is not set. \n",
    "\n",
    "1) Use one classification method on the dataset. You can apply any of the methods explained in this instruction notebook or any other method in scikit-learn. You can even implement your own method. You can tune your model by using any combination of parameter values. Use 75% of the data for training and the rest for testing.\n",
    "\n",
    "2) Print out the accuracy of the model in 1).\n",
    "\n",
    "3) Print out the confusion matrix for the model in 1). Note that we are dealing with a multi-class (5 basketball positions) classification problem. So the confusion matrix should be 5 x 5. (Actually 6 x 6 since we are also printing the numbers of \"All\". Refer to the earlier example.)\n",
    "\n",
    "4) Use the same model with the same parameters you have chosen in 1). However, instead of using 75%/25% train/test split, apply 10-fold stratified cross-validation. \n",
    "\n",
    "5) Print out the accuracy of each fold in 4).\n",
    "\n",
    "6) Print out the average accuracy across all the folds in 4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grading and Tips\n",
    "\n",
    "For this assignment, the most important thing is to carefully read the instruction notebook and play with the code snippets. The concepts and ideas discussed in the instructions have all been discussed in lectures. Referring to the lecture slides/videos can help you if you face challenges in understanding the instructions. Once you understand the instructions and the code snippets, it won't be difficult to finish the tasks. \n",
    "\n",
    "You will mainly be evaluated on whether you can accomplish the given tasks. Furthermore, 30% of the total score will be based on the accuracy of your model. This way, we believe you can achieve 70% of the score without much struggle and you may have fun trying to improve it. \n",
    "\n",
    "Below are some thoughts on what might lead to better accuracy. Note that we haven't tried all these ideas. There is no promise they will help you. \n",
    "\n",
    "1) The features may not be all equally important. For instance, is 'Age' important for this classification task? Some of the features are redundant. For instance, field goal percentage (FG%) is defined by field goals made (FG) and field goal attempts (FGA): FG% = FG / FGA. It may not be beneficial to include all of them. \n",
    "\n",
    "Some domain knowledge might help you in choosing the features. To understand basketball stats, you can click \"Glossary\" on this page: http://www.basketball-reference.com/leagues/NBA_2016_per_game.html. You can read more about basketball stats: https://en.wikipedia.org/wiki/Basketball_statistics. \n",
    "\n",
    "Of course, it might be possible to devise a way to automatically choose features. \n",
    "\n",
    "2) It might be helpful to understand the classes, i.e., the 5 positions on court. You can read https://en.wikipedia.org/wiki/Basketball_positions. For instance, SG and PG players are more likely to have similar stats; PF and C can be also similar; some SFs are similar to SG/PG and some other SFs are similar to PF.  \n",
    "\n",
    "3) The original dataset has NULL values. For instance, if a player has never attempted a 3-pointer shot (i.e., 3PA=0), then of course he didn't make any 3-pointer shot either (i.e., 3P=0). The value of \"3P%\" was left blank in the original dataset. We replaced it by 0. Knowing this might be helpful. Similarly there can be NULL values in FG%, FT%, and so on. \n",
    "\n",
    "4) Keep in mind that stats of players with limited minutes played are less indicative of their true characteristics. You can expect your model to make more mistakes on bench players. For the same reason, we don't expect you to develop some model with 90% accuracy. (But who knows. You are excellent and maybe you can exceed the expectation.) \n",
    "\n",
    "5) If your method relies on a distance measure, you may consider writing your own distance function, based on your understanding of the data. For instance, KNeighborsClassifier allows you to call your own distance function. \n",
    "\n",
    "6) To figure out what parameters are available in the various classification methods, you can read more about the specifications of the corresponding Python classes: \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "You can even read the following tutorials about these methods. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_metadata": {
   "author": "Chengkai Li",
   "title": "CSE4334 P2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
